{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import music21\n",
    "from music21 import converter, instrument, note, chord, midi, stream\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "Here are parameters you can edit in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory length -- each new note is generated by considering this many previous notes\n",
    "sequence_length = 20\n",
    "\n",
    "# How many rounds of training to perform -- more training will likely provide better performance\n",
    "training_rounds = 20\n",
    "\n",
    "# Where to ouput the generated file\n",
    "output_file = \"output.mid\"\n",
    "\n",
    "# Number of output notes to generate\n",
    "numberOutputNotes = 200\n",
    "\n",
    "# Save model checkpoints\n",
    "saveModel = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "First we must load the data from the songs. To do this, we'll go through all the songs in our training data of MIDI files. We parse them with music21 to get the individual notes. If the element is a chord, then it is converted to it's numerical representation. After this step we will have all of the notes/chords that appear in string form, and a corresponding vocabulary as a set of them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 1 Loaded\n",
      "Song 2 Loaded\n",
      "DONE LOADING SONGS\n",
      "I found 3098 notes\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "track = 0\n",
    "\n",
    "files = glob.glob(\"input*.mid\")\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    midi = converter.parse(file)\n",
    "    # There are multiple tracks in the MIDI file, so we'll use the first one\n",
    "    midi = midi[track]\n",
    "    notes_to_parse = None\n",
    "        \n",
    "    # Parse the midi file by the notes it contains\n",
    "    notes_to_parse = midi.flat.notes\n",
    "        \n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, music21.note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            # get's the normal order (numerical representation) of the chord\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    print(\"Song {} Loaded\".format(i+1))\n",
    "                \n",
    "print(\"DONE LOADING SONGS\")    \n",
    "# Get all pitch names\n",
    "pitches = sorted(set(item for item in notes))\n",
    "# Get all pitch names\n",
    "vocab_length = len(pitches)  \n",
    "number_notes = len(notes)\n",
    "# print(vocab_length)\n",
    "# print(notes)\n",
    "# print(len(notes))\n",
    "print(f'I found {number_notes} notes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(notes) > sequence_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must get these notes in a usable form for our LSTM. Let's construct sequences that can be grouped together to predict the next note in groups of 10 notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use One Hot Encoding for each of the notes and create an array as such of sequences. \n",
    "#Let's first assign an index to each of the possible notes\n",
    "note_dict = dict()\n",
    "for i, note in enumerate(pitches):\n",
    "    note_dict[note] = i\n",
    "#print(note_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Lets make a numpy array with the number of training examples, sequence length, and the length of the one-hot-encoding\n",
    "num_training = number_notes - sequence_length\n",
    "\n",
    "input_notes = np.zeros((num_training, sequence_length, vocab_length))\n",
    "output_notes = np.zeros((num_training, vocab_length))\n",
    "\n",
    "for i in range(0, num_training):\n",
    "    # Here, i is the training example, j is the note in the sequence for a specific training example\n",
    "    input_sequence = notes[i: i+sequence_length]\n",
    "    output_note = notes[i+sequence_length]\n",
    "    for j, note in enumerate(input_sequence):\n",
    "        input_notes[i][j][note_dict[note]] = 1\n",
    "    output_notes[i][note_dict[output_note]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 4.5096 - acc: 0.0404\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.04037, saving model to weights-improvement-01-0.04.hdf5\n",
      "Epoch 2/300\n",
      "2898/2898 [==============================] - 20s 7ms/step - loss: 4.2462 - acc: 0.0480\n",
      "\n",
      "Epoch 00002: acc improved from 0.04037 to 0.04796, saving model to weights-improvement-02-0.05.hdf5\n",
      "Epoch 3/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 4.1558 - acc: 0.0566\n",
      "\n",
      "Epoch 00003: acc improved from 0.04796 to 0.05659, saving model to weights-improvement-03-0.06.hdf5\n",
      "Epoch 4/300\n",
      "2898/2898 [==============================] - 20s 7ms/step - loss: 4.0597 - acc: 0.0659\n",
      "\n",
      "Epoch 00004: acc improved from 0.05659 to 0.06591, saving model to weights-improvement-04-0.07.hdf5\n",
      "Epoch 5/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 3.9234 - acc: 0.0759\n",
      "\n",
      "Epoch 00005: acc improved from 0.06591 to 0.07591, saving model to weights-improvement-05-0.08.hdf5\n",
      "Epoch 6/300\n",
      "2898/2898 [==============================] - 20s 7ms/step - loss: 3.8573 - acc: 0.0718\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.07591\n",
      "Epoch 7/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 3.7839 - acc: 0.0742\n",
      "\n",
      "Epoch 00007: acc did not improve from 0.07591\n",
      "Epoch 8/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 3.7034 - acc: 0.0832\n",
      "\n",
      "Epoch 00008: acc improved from 0.07591 to 0.08316, saving model to weights-improvement-08-0.08.hdf5\n",
      "Epoch 9/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 3.6226 - acc: 0.1011\n",
      "\n",
      "Epoch 00009: acc improved from 0.08316 to 0.10110, saving model to weights-improvement-09-0.10.hdf5\n",
      "Epoch 10/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 3.5651 - acc: 0.0973\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.10110\n",
      "Epoch 11/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 3.5184 - acc: 0.1001\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.10110\n",
      "Epoch 12/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 3.4503 - acc: 0.1035\n",
      "\n",
      "Epoch 00012: acc improved from 0.10110 to 0.10352, saving model to weights-improvement-12-0.10.hdf5\n",
      "Epoch 13/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 3.3738 - acc: 0.1173\n",
      "\n",
      "Epoch 00013: acc improved from 0.10352 to 0.11732, saving model to weights-improvement-13-0.12.hdf5\n",
      "Epoch 14/300\n",
      "2898/2898 [==============================] - 31s 11ms/step - loss: 3.3160 - acc: 0.1273\n",
      "\n",
      "Epoch 00014: acc improved from 0.11732 to 0.12733, saving model to weights-improvement-14-0.13.hdf5\n",
      "Epoch 15/300\n",
      "2898/2898 [==============================] - 33s 11ms/step - loss: 3.2538 - acc: 0.1325\n",
      "\n",
      "Epoch 00015: acc improved from 0.12733 to 0.13251, saving model to weights-improvement-15-0.13.hdf5\n",
      "Epoch 16/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 3.1926 - acc: 0.1329\n",
      "\n",
      "Epoch 00016: acc improved from 0.13251 to 0.13285, saving model to weights-improvement-16-0.13.hdf5\n",
      "Epoch 17/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 3.1512 - acc: 0.1387\n",
      "\n",
      "Epoch 00017: acc improved from 0.13285 to 0.13872, saving model to weights-improvement-17-0.14.hdf5\n",
      "Epoch 18/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 3.1053 - acc: 0.1467\n",
      "\n",
      "Epoch 00018: acc improved from 0.13872 to 0.14665, saving model to weights-improvement-18-0.15.hdf5\n",
      "Epoch 19/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 3.0491 - acc: 0.1480\n",
      "\n",
      "Epoch 00019: acc improved from 0.14665 to 0.14803, saving model to weights-improvement-19-0.15.hdf5\n",
      "Epoch 20/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.9977 - acc: 0.1639\n",
      "\n",
      "Epoch 00020: acc improved from 0.14803 to 0.16391, saving model to weights-improvement-20-0.16.hdf5\n",
      "Epoch 21/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 2.9485 - acc: 0.1587\n",
      "\n",
      "Epoch 00021: acc did not improve from 0.16391\n",
      "Epoch 22/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.9084 - acc: 0.1636\n",
      "\n",
      "Epoch 00022: acc did not improve from 0.16391\n",
      "Epoch 23/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 2.8659 - acc: 0.1715\n",
      "\n",
      "Epoch 00023: acc improved from 0.16391 to 0.17150, saving model to weights-improvement-23-0.17.hdf5\n",
      "Epoch 24/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.8420 - acc: 0.1784\n",
      "\n",
      "Epoch 00024: acc improved from 0.17150 to 0.17840, saving model to weights-improvement-24-0.18.hdf5\n",
      "Epoch 25/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 2.8185 - acc: 0.1767\n",
      "\n",
      "Epoch 00025: acc did not improve from 0.17840\n",
      "Epoch 26/300\n",
      "2898/2898 [==============================] - 32s 11ms/step - loss: 2.7665 - acc: 0.1808\n",
      "\n",
      "Epoch 00026: acc improved from 0.17840 to 0.18081, saving model to weights-improvement-26-0.18.hdf5\n",
      "Epoch 27/300\n",
      "2898/2898 [==============================] - 33s 11ms/step - loss: 2.7467 - acc: 0.1860\n",
      "\n",
      "Epoch 00027: acc improved from 0.18081 to 0.18599, saving model to weights-improvement-27-0.19.hdf5\n",
      "Epoch 28/300\n",
      "2898/2898 [==============================] - 43s 15ms/step - loss: 2.7086 - acc: 0.1901\n",
      "\n",
      "Epoch 00028: acc improved from 0.18599 to 0.19013, saving model to weights-improvement-28-0.19.hdf5\n",
      "Epoch 29/300\n",
      "2898/2898 [==============================] - 34s 12ms/step - loss: 2.6689 - acc: 0.1870\n",
      "\n",
      "Epoch 00029: acc did not improve from 0.19013\n",
      "Epoch 30/300\n",
      "2898/2898 [==============================] - 27s 9ms/step - loss: 2.6547 - acc: 0.1988\n",
      "\n",
      "Epoch 00030: acc improved from 0.19013 to 0.19876, saving model to weights-improvement-30-0.20.hdf5\n",
      "Epoch 31/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 2.6098 - acc: 0.2060\n",
      "\n",
      "Epoch 00031: acc improved from 0.19876 to 0.20600, saving model to weights-improvement-31-0.21.hdf5\n",
      "Epoch 32/300\n",
      "2898/2898 [==============================] - 27s 9ms/step - loss: 2.5994 - acc: 0.2012\n",
      "\n",
      "Epoch 00032: acc did not improve from 0.20600\n",
      "Epoch 33/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.5614 - acc: 0.2174\n",
      "\n",
      "Epoch 00033: acc improved from 0.20600 to 0.21739, saving model to weights-improvement-33-0.22.hdf5\n",
      "Epoch 34/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.5513 - acc: 0.2129\n",
      "\n",
      "Epoch 00034: acc did not improve from 0.21739\n",
      "Epoch 35/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.5198 - acc: 0.2157\n",
      "\n",
      "Epoch 00035: acc did not improve from 0.21739\n",
      "Epoch 36/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 2.4858 - acc: 0.2222\n",
      "\n",
      "Epoch 00036: acc improved from 0.21739 to 0.22222, saving model to weights-improvement-36-0.22.hdf5\n",
      "Epoch 37/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.4771 - acc: 0.2260\n",
      "\n",
      "Epoch 00037: acc improved from 0.22222 to 0.22602, saving model to weights-improvement-37-0.23.hdf5\n",
      "Epoch 38/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.4411 - acc: 0.2208\n",
      "\n",
      "Epoch 00038: acc did not improve from 0.22602\n",
      "Epoch 39/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.4244 - acc: 0.2243\n",
      "\n",
      "Epoch 00039: acc did not improve from 0.22602\n",
      "Epoch 40/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.3936 - acc: 0.2484\n",
      "\n",
      "Epoch 00040: acc improved from 0.22602 to 0.24845, saving model to weights-improvement-40-0.25.hdf5\n",
      "Epoch 41/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 2.3609 - acc: 0.2402\n",
      "\n",
      "Epoch 00041: acc did not improve from 0.24845\n",
      "Epoch 42/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 2.3415 - acc: 0.2498\n",
      "\n",
      "Epoch 00042: acc improved from 0.24845 to 0.24983, saving model to weights-improvement-42-0.25.hdf5\n",
      "Epoch 43/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.3593 - acc: 0.2429\n",
      "\n",
      "Epoch 00043: acc did not improve from 0.24983\n",
      "Epoch 44/300\n",
      "2898/2898 [==============================] - 25s 8ms/step - loss: 2.3104 - acc: 0.2505\n",
      "\n",
      "Epoch 00044: acc improved from 0.24983 to 0.25052, saving model to weights-improvement-44-0.25.hdf5\n",
      "Epoch 45/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.3023 - acc: 0.2588\n",
      "\n",
      "Epoch 00045: acc improved from 0.25052 to 0.25880, saving model to weights-improvement-45-0.26.hdf5\n",
      "Epoch 46/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898/2898 [==============================] - 25s 9ms/step - loss: 2.2585 - acc: 0.2723\n",
      "\n",
      "Epoch 00046: acc improved from 0.25880 to 0.27226, saving model to weights-improvement-46-0.27.hdf5\n",
      "Epoch 47/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.2631 - acc: 0.2692\n",
      "\n",
      "Epoch 00047: acc did not improve from 0.27226\n",
      "Epoch 48/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.2414 - acc: 0.2702\n",
      "\n",
      "Epoch 00048: acc did not improve from 0.27226\n",
      "Epoch 49/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 2.2359 - acc: 0.2640\n",
      "\n",
      "Epoch 00049: acc did not improve from 0.27226\n",
      "Epoch 50/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.1941 - acc: 0.2823\n",
      "\n",
      "Epoch 00050: acc improved from 0.27226 to 0.28226, saving model to weights-improvement-50-0.28.hdf5\n",
      "Epoch 51/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.2079 - acc: 0.2736\n",
      "\n",
      "Epoch 00051: acc did not improve from 0.28226\n",
      "Epoch 52/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.1737 - acc: 0.2778\n",
      "\n",
      "Epoch 00052: acc did not improve from 0.28226\n",
      "Epoch 53/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.1668 - acc: 0.2823\n",
      "\n",
      "Epoch 00053: acc did not improve from 0.28226\n",
      "Epoch 54/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 2.1307 - acc: 0.2905\n",
      "\n",
      "Epoch 00054: acc improved from 0.28226 to 0.29055, saving model to weights-improvement-54-0.29.hdf5\n",
      "Epoch 55/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 2.1110 - acc: 0.2940\n",
      "\n",
      "Epoch 00055: acc improved from 0.29055 to 0.29400, saving model to weights-improvement-55-0.29.hdf5\n",
      "Epoch 56/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.1052 - acc: 0.2836\n",
      "\n",
      "Epoch 00056: acc did not improve from 0.29400\n",
      "Epoch 57/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.0898 - acc: 0.3002\n",
      "\n",
      "Epoch 00057: acc improved from 0.29400 to 0.30021, saving model to weights-improvement-57-0.30.hdf5\n",
      "Epoch 58/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 2.0811 - acc: 0.3030\n",
      "\n",
      "Epoch 00058: acc improved from 0.30021 to 0.30297, saving model to weights-improvement-58-0.30.hdf5\n",
      "Epoch 59/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.0639 - acc: 0.3106\n",
      "\n",
      "Epoch 00059: acc improved from 0.30297 to 0.31056, saving model to weights-improvement-59-0.31.hdf5\n",
      "Epoch 60/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.0501 - acc: 0.3116\n",
      "\n",
      "Epoch 00060: acc improved from 0.31056 to 0.31159, saving model to weights-improvement-60-0.31.hdf5\n",
      "Epoch 61/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 2.0217 - acc: 0.3116\n",
      "\n",
      "Epoch 00061: acc improved from 0.31159 to 0.31159, saving model to weights-improvement-61-0.31.hdf5\n",
      "Epoch 62/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.0292 - acc: 0.3075\n",
      "\n",
      "Epoch 00062: acc did not improve from 0.31159\n",
      "Epoch 63/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 2.0016 - acc: 0.3247\n",
      "\n",
      "Epoch 00063: acc improved from 0.31159 to 0.32471, saving model to weights-improvement-63-0.32.hdf5\n",
      "Epoch 64/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.9801 - acc: 0.3233\n",
      "\n",
      "Epoch 00064: acc did not improve from 0.32471\n",
      "Epoch 65/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.9808 - acc: 0.3230\n",
      "\n",
      "Epoch 00065: acc did not improve from 0.32471\n",
      "Epoch 66/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.9819 - acc: 0.3147\n",
      "\n",
      "Epoch 00066: acc did not improve from 0.32471\n",
      "Epoch 67/300\n",
      "2898/2898 [==============================] - 25s 8ms/step - loss: 1.9672 - acc: 0.3088\n",
      "\n",
      "Epoch 00067: acc did not improve from 0.32471\n",
      "Epoch 68/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.9373 - acc: 0.3295\n",
      "\n",
      "Epoch 00068: acc improved from 0.32471 to 0.32954, saving model to weights-improvement-68-0.33.hdf5\n",
      "Epoch 69/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.9338 - acc: 0.3282\n",
      "\n",
      "Epoch 00069: acc did not improve from 0.32954\n",
      "Epoch 70/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.9315 - acc: 0.3257\n",
      "\n",
      "Epoch 00070: acc did not improve from 0.32954\n",
      "Epoch 71/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.9007 - acc: 0.3357\n",
      "\n",
      "Epoch 00071: acc improved from 0.32954 to 0.33575, saving model to weights-improvement-71-0.34.hdf5\n",
      "Epoch 72/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.9011 - acc: 0.3361\n",
      "\n",
      "Epoch 00072: acc improved from 0.33575 to 0.33609, saving model to weights-improvement-72-0.34.hdf5\n",
      "Epoch 73/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.8734 - acc: 0.3423\n",
      "\n",
      "Epoch 00073: acc improved from 0.33609 to 0.34231, saving model to weights-improvement-73-0.34.hdf5\n",
      "Epoch 74/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 1.8774 - acc: 0.3364\n",
      "\n",
      "Epoch 00074: acc did not improve from 0.34231\n",
      "Epoch 75/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.8673 - acc: 0.3433\n",
      "\n",
      "Epoch 00075: acc improved from 0.34231 to 0.34334, saving model to weights-improvement-75-0.34.hdf5\n",
      "Epoch 76/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.8457 - acc: 0.3565\n",
      "\n",
      "Epoch 00076: acc improved from 0.34334 to 0.35645, saving model to weights-improvement-76-0.36.hdf5\n",
      "Epoch 77/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.8410 - acc: 0.3544\n",
      "\n",
      "Epoch 00077: acc did not improve from 0.35645\n",
      "Epoch 78/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.8483 - acc: 0.3440\n",
      "\n",
      "Epoch 00078: acc did not improve from 0.35645\n",
      "Epoch 79/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.8105 - acc: 0.3451\n",
      "\n",
      "Epoch 00079: acc did not improve from 0.35645\n",
      "Epoch 80/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.8108 - acc: 0.3554\n",
      "\n",
      "Epoch 00080: acc did not improve from 0.35645\n",
      "Epoch 81/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.8173 - acc: 0.3571\n",
      "\n",
      "Epoch 00081: acc improved from 0.35645 to 0.35714, saving model to weights-improvement-81-0.36.hdf5\n",
      "Epoch 82/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.7748 - acc: 0.3782\n",
      "\n",
      "Epoch 00082: acc improved from 0.35714 to 0.37819, saving model to weights-improvement-82-0.38.hdf5\n",
      "Epoch 83/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.7773 - acc: 0.3520\n",
      "\n",
      "Epoch 00083: acc did not improve from 0.37819\n",
      "Epoch 84/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.7520 - acc: 0.3665\n",
      "\n",
      "Epoch 00084: acc did not improve from 0.37819\n",
      "Epoch 85/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.7585 - acc: 0.3637\n",
      "\n",
      "Epoch 00085: acc did not improve from 0.37819\n",
      "Epoch 86/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.7431 - acc: 0.3830\n",
      "\n",
      "Epoch 00086: acc improved from 0.37819 to 0.38302, saving model to weights-improvement-86-0.38.hdf5\n",
      "Epoch 87/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.7409 - acc: 0.3716\n",
      "\n",
      "Epoch 00087: acc did not improve from 0.38302\n",
      "Epoch 88/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.7050 - acc: 0.3986\n",
      "\n",
      "Epoch 00088: acc improved from 0.38302 to 0.39855, saving model to weights-improvement-88-0.40.hdf5\n",
      "Epoch 89/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.7003 - acc: 0.3837\n",
      "\n",
      "Epoch 00089: acc did not improve from 0.39855\n",
      "Epoch 90/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.6994 - acc: 0.3851\n",
      "\n",
      "Epoch 00090: acc did not improve from 0.39855\n",
      "Epoch 91/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.6933 - acc: 0.3854\n",
      "\n",
      "Epoch 00091: acc did not improve from 0.39855\n",
      "Epoch 92/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.6784 - acc: 0.3941\n",
      "\n",
      "Epoch 00092: acc did not improve from 0.39855\n",
      "Epoch 93/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.6688 - acc: 0.3889\n",
      "\n",
      "Epoch 00093: acc did not improve from 0.39855\n",
      "Epoch 94/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.6576 - acc: 0.3989\n",
      "\n",
      "Epoch 00094: acc improved from 0.39855 to 0.39890, saving model to weights-improvement-94-0.40.hdf5\n",
      "Epoch 95/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.6929 - acc: 0.4023\n",
      "\n",
      "Epoch 00095: acc improved from 0.39890 to 0.40235, saving model to weights-improvement-95-0.40.hdf5\n",
      "Epoch 96/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.6301 - acc: 0.4041\n",
      "\n",
      "Epoch 00096: acc improved from 0.40235 to 0.40407, saving model to weights-improvement-96-0.40.hdf5\n",
      "Epoch 97/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.6354 - acc: 0.3992\n",
      "\n",
      "Epoch 00097: acc did not improve from 0.40407\n",
      "Epoch 98/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.6100 - acc: 0.4155\n",
      "\n",
      "Epoch 00098: acc improved from 0.40407 to 0.41546, saving model to weights-improvement-98-0.42.hdf5\n",
      "Epoch 99/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.6321 - acc: 0.4051\n",
      "\n",
      "Epoch 00099: acc did not improve from 0.41546\n",
      "Epoch 100/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.5868 - acc: 0.4199\n",
      "\n",
      "Epoch 00100: acc improved from 0.41546 to 0.41994, saving model to weights-improvement-100-0.42.hdf5\n",
      "Epoch 101/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.6087 - acc: 0.4058\n",
      "\n",
      "Epoch 00101: acc did not improve from 0.41994\n",
      "Epoch 102/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 1.5945 - acc: 0.4141\n",
      "\n",
      "Epoch 00102: acc did not improve from 0.41994\n",
      "Epoch 103/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 1.5992 - acc: 0.4168\n",
      "\n",
      "Epoch 00103: acc did not improve from 0.41994\n",
      "Epoch 104/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.5819 - acc: 0.4189\n",
      "\n",
      "Epoch 00104: acc did not improve from 0.41994\n",
      "Epoch 105/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 1.5710 - acc: 0.4179\n",
      "\n",
      "Epoch 00105: acc did not improve from 0.41994\n",
      "Epoch 106/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.5586 - acc: 0.4151\n",
      "\n",
      "Epoch 00106: acc did not improve from 0.41994\n",
      "Epoch 107/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.5532 - acc: 0.4293\n",
      "\n",
      "Epoch 00107: acc improved from 0.41994 to 0.42926, saving model to weights-improvement-107-0.43.hdf5\n",
      "Epoch 108/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.5398 - acc: 0.4358\n",
      "\n",
      "Epoch 00108: acc improved from 0.42926 to 0.43582, saving model to weights-improvement-108-0.44.hdf5\n",
      "Epoch 109/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.5252 - acc: 0.4355\n",
      "\n",
      "Epoch 00109: acc did not improve from 0.43582\n",
      "Epoch 110/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.5178 - acc: 0.4406\n",
      "\n",
      "Epoch 00110: acc improved from 0.43582 to 0.44065, saving model to weights-improvement-110-0.44.hdf5\n",
      "Epoch 111/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.4972 - acc: 0.4600\n",
      "\n",
      "Epoch 00111: acc improved from 0.44065 to 0.45997, saving model to weights-improvement-111-0.46.hdf5\n",
      "Epoch 112/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 1.5087 - acc: 0.4406\n",
      "\n",
      "Epoch 00112: acc did not improve from 0.45997\n",
      "Epoch 113/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.4813 - acc: 0.4572\n",
      "\n",
      "Epoch 00113: acc did not improve from 0.45997\n",
      "Epoch 114/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.4469 - acc: 0.4658\n",
      "\n",
      "Epoch 00114: acc improved from 0.45997 to 0.46584, saving model to weights-improvement-114-0.47.hdf5\n",
      "Epoch 115/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.4760 - acc: 0.4593\n",
      "\n",
      "Epoch 00115: acc did not improve from 0.46584\n",
      "Epoch 116/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.4724 - acc: 0.4489\n",
      "\n",
      "Epoch 00116: acc did not improve from 0.46584\n",
      "Epoch 117/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.4504 - acc: 0.4738\n",
      "\n",
      "Epoch 00117: acc improved from 0.46584 to 0.47378, saving model to weights-improvement-117-0.47.hdf5\n",
      "Epoch 118/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.4313 - acc: 0.4655\n",
      "\n",
      "Epoch 00118: acc did not improve from 0.47378\n",
      "Epoch 119/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.4261 - acc: 0.4800\n",
      "\n",
      "Epoch 00119: acc improved from 0.47378 to 0.47999, saving model to weights-improvement-119-0.48.hdf5\n",
      "Epoch 120/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 1.4192 - acc: 0.4693\n",
      "\n",
      "Epoch 00120: acc did not improve from 0.47999\n",
      "Epoch 121/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.4237 - acc: 0.4841\n",
      "\n",
      "Epoch 00121: acc improved from 0.47999 to 0.48413, saving model to weights-improvement-121-0.48.hdf5\n",
      "Epoch 122/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.4000 - acc: 0.4869\n",
      "\n",
      "Epoch 00122: acc improved from 0.48413 to 0.48689, saving model to weights-improvement-122-0.49.hdf5\n",
      "Epoch 123/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.4044 - acc: 0.4738\n",
      "\n",
      "Epoch 00123: acc did not improve from 0.48689\n",
      "Epoch 124/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.3820 - acc: 0.4883\n",
      "\n",
      "Epoch 00124: acc improved from 0.48689 to 0.48827, saving model to weights-improvement-124-0.49.hdf5\n",
      "Epoch 125/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.3789 - acc: 0.4917\n",
      "\n",
      "Epoch 00125: acc improved from 0.48827 to 0.49172, saving model to weights-improvement-125-0.49.hdf5\n",
      "Epoch 126/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.3554 - acc: 0.4959\n",
      "\n",
      "Epoch 00126: acc improved from 0.49172 to 0.49586, saving model to weights-improvement-126-0.50.hdf5\n",
      "Epoch 127/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.3410 - acc: 0.5017\n",
      "\n",
      "Epoch 00127: acc improved from 0.49586 to 0.50173, saving model to weights-improvement-127-0.50.hdf5\n",
      "Epoch 128/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.3586 - acc: 0.4938\n",
      "\n",
      "Epoch 00128: acc did not improve from 0.50173\n",
      "Epoch 129/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.3440 - acc: 0.4907\n",
      "\n",
      "Epoch 00129: acc did not improve from 0.50173\n",
      "Epoch 130/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.3415 - acc: 0.5169\n",
      "\n",
      "Epoch 00130: acc improved from 0.50173 to 0.51691, saving model to weights-improvement-130-0.52.hdf5\n",
      "Epoch 131/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.3061 - acc: 0.5176\n",
      "\n",
      "Epoch 00131: acc improved from 0.51691 to 0.51760, saving model to weights-improvement-131-0.52.hdf5\n",
      "Epoch 132/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.3001 - acc: 0.5204\n",
      "\n",
      "Epoch 00132: acc improved from 0.51760 to 0.52036, saving model to weights-improvement-132-0.52.hdf5\n",
      "Epoch 133/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.3023 - acc: 0.5159\n",
      "\n",
      "Epoch 00133: acc did not improve from 0.52036\n",
      "Epoch 134/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.2909 - acc: 0.5159\n",
      "\n",
      "Epoch 00134: acc did not improve from 0.52036\n",
      "Epoch 135/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.2802 - acc: 0.5293\n",
      "\n",
      "Epoch 00135: acc improved from 0.52036 to 0.52933, saving model to weights-improvement-135-0.53.hdf5\n",
      "Epoch 136/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.2777 - acc: 0.5266\n",
      "\n",
      "Epoch 00136: acc did not improve from 0.52933\n",
      "Epoch 137/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.2809 - acc: 0.5224\n",
      "\n",
      "Epoch 00137: acc did not improve from 0.52933\n",
      "Epoch 138/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.2557 - acc: 0.5362\n",
      "\n",
      "Epoch 00138: acc improved from 0.52933 to 0.53623, saving model to weights-improvement-138-0.54.hdf5\n",
      "Epoch 139/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 1.2704 - acc: 0.5293\n",
      "\n",
      "Epoch 00139: acc did not improve from 0.53623\n",
      "Epoch 140/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.2328 - acc: 0.5528\n",
      "\n",
      "Epoch 00140: acc improved from 0.53623 to 0.55280, saving model to weights-improvement-140-0.55.hdf5\n",
      "Epoch 141/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.2401 - acc: 0.5428\n",
      "\n",
      "Epoch 00141: acc did not improve from 0.55280\n",
      "Epoch 142/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.2301 - acc: 0.5338\n",
      "\n",
      "Epoch 00142: acc did not improve from 0.55280\n",
      "Epoch 143/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 1.2308 - acc: 0.5469\n",
      "\n",
      "Epoch 00143: acc did not improve from 0.55280\n",
      "Epoch 144/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.2186 - acc: 0.5497\n",
      "\n",
      "Epoch 00144: acc did not improve from 0.55280\n",
      "Epoch 145/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.2083 - acc: 0.5645\n",
      "\n",
      "Epoch 00145: acc improved from 0.55280 to 0.56453, saving model to weights-improvement-145-0.56.hdf5\n",
      "Epoch 146/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.1665 - acc: 0.5652\n",
      "\n",
      "Epoch 00146: acc improved from 0.56453 to 0.56522, saving model to weights-improvement-146-0.57.hdf5\n",
      "Epoch 147/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.1919 - acc: 0.5604\n",
      "\n",
      "Epoch 00147: acc did not improve from 0.56522\n",
      "Epoch 148/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.1774 - acc: 0.5697\n",
      "\n",
      "Epoch 00148: acc improved from 0.56522 to 0.56970, saving model to weights-improvement-148-0.57.hdf5\n",
      "Epoch 149/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.1573 - acc: 0.5773\n",
      "\n",
      "Epoch 00149: acc improved from 0.56970 to 0.57729, saving model to weights-improvement-149-0.58.hdf5\n",
      "Epoch 150/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.1544 - acc: 0.5728\n",
      "\n",
      "Epoch 00150: acc did not improve from 0.57729\n",
      "Epoch 151/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.1674 - acc: 0.5721\n",
      "\n",
      "Epoch 00151: acc did not improve from 0.57729\n",
      "Epoch 152/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.1348 - acc: 0.5825\n",
      "\n",
      "Epoch 00152: acc improved from 0.57729 to 0.58247, saving model to weights-improvement-152-0.58.hdf5\n",
      "Epoch 153/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.1428 - acc: 0.5769\n",
      "\n",
      "Epoch 00153: acc did not improve from 0.58247\n",
      "Epoch 154/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.1223 - acc: 0.5945\n",
      "\n",
      "Epoch 00154: acc improved from 0.58247 to 0.59455, saving model to weights-improvement-154-0.59.hdf5\n",
      "Epoch 155/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.1236 - acc: 0.5821\n",
      "\n",
      "Epoch 00155: acc did not improve from 0.59455\n",
      "Epoch 156/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 1.0952 - acc: 0.6025\n",
      "\n",
      "Epoch 00156: acc improved from 0.59455 to 0.60248, saving model to weights-improvement-156-0.60.hdf5\n",
      "Epoch 157/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.0885 - acc: 0.6104\n",
      "\n",
      "Epoch 00157: acc improved from 0.60248 to 0.61042, saving model to weights-improvement-157-0.61.hdf5\n",
      "Epoch 158/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.1051 - acc: 0.5883\n",
      "\n",
      "Epoch 00158: acc did not improve from 0.61042\n",
      "Epoch 159/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.0822 - acc: 0.6128\n",
      "\n",
      "Epoch 00159: acc improved from 0.61042 to 0.61284, saving model to weights-improvement-159-0.61.hdf5\n",
      "Epoch 160/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 1.0855 - acc: 0.6070\n",
      "\n",
      "Epoch 00160: acc did not improve from 0.61284\n",
      "Epoch 161/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 1.0626 - acc: 0.6177\n",
      "\n",
      "Epoch 00161: acc improved from 0.61284 to 0.61767, saving model to weights-improvement-161-0.62.hdf5\n",
      "Epoch 162/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.0488 - acc: 0.6266\n",
      "\n",
      "Epoch 00162: acc improved from 0.61767 to 0.62664, saving model to weights-improvement-162-0.63.hdf5\n",
      "Epoch 163/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 1.0498 - acc: 0.6146\n",
      "\n",
      "Epoch 00163: acc did not improve from 0.62664\n",
      "Epoch 164/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.0603 - acc: 0.6297\n",
      "\n",
      "Epoch 00164: acc improved from 0.62664 to 0.62974, saving model to weights-improvement-164-0.63.hdf5\n",
      "Epoch 165/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.0399 - acc: 0.6187\n",
      "\n",
      "Epoch 00165: acc did not improve from 0.62974\n",
      "Epoch 166/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 1.0255 - acc: 0.6249\n",
      "\n",
      "Epoch 00166: acc did not improve from 0.62974\n",
      "Epoch 167/300\n",
      "2898/2898 [==============================] - 29s 10ms/step - loss: 1.0251 - acc: 0.6204\n",
      "\n",
      "Epoch 00167: acc did not improve from 0.62974\n",
      "Epoch 168/300\n",
      "2898/2898 [==============================] - 25s 8ms/step - loss: 0.9974 - acc: 0.6404\n",
      "\n",
      "Epoch 00168: acc improved from 0.62974 to 0.64044, saving model to weights-improvement-168-0.64.hdf5\n",
      "Epoch 169/300\n",
      "2898/2898 [==============================] - 28s 10ms/step - loss: 1.0006 - acc: 0.6391\n",
      "\n",
      "Epoch 00169: acc did not improve from 0.64044\n",
      "Epoch 170/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.9931 - acc: 0.6415\n",
      "\n",
      "Epoch 00170: acc improved from 0.64044 to 0.64148, saving model to weights-improvement-170-0.64.hdf5\n",
      "Epoch 171/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.9955 - acc: 0.6346\n",
      "\n",
      "Epoch 00171: acc did not improve from 0.64148\n",
      "Epoch 172/300\n",
      "2898/2898 [==============================] - 29s 10ms/step - loss: 0.9936 - acc: 0.6366\n",
      "\n",
      "Epoch 00172: acc did not improve from 0.64148\n",
      "Epoch 173/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.9765 - acc: 0.6480\n",
      "\n",
      "Epoch 00173: acc improved from 0.64148 to 0.64803, saving model to weights-improvement-173-0.65.hdf5\n",
      "Epoch 174/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.9362 - acc: 0.6584\n",
      "\n",
      "Epoch 00174: acc improved from 0.64803 to 0.65839, saving model to weights-improvement-174-0.66.hdf5\n",
      "Epoch 175/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.9586 - acc: 0.6536\n",
      "\n",
      "Epoch 00175: acc did not improve from 0.65839\n",
      "Epoch 176/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.9417 - acc: 0.6591\n",
      "\n",
      "Epoch 00176: acc improved from 0.65839 to 0.65908, saving model to weights-improvement-176-0.66.hdf5\n",
      "Epoch 177/300\n",
      "2898/2898 [==============================] - 28s 10ms/step - loss: 0.9480 - acc: 0.6553\n",
      "\n",
      "Epoch 00177: acc did not improve from 0.65908\n",
      "Epoch 178/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.9546 - acc: 0.6425\n",
      "\n",
      "Epoch 00178: acc did not improve from 0.65908\n",
      "Epoch 179/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.9311 - acc: 0.6701\n",
      "\n",
      "Epoch 00179: acc improved from 0.65908 to 0.67012, saving model to weights-improvement-179-0.67.hdf5\n",
      "Epoch 180/300\n",
      "2898/2898 [==============================] - 28s 10ms/step - loss: 0.9210 - acc: 0.6743\n",
      "\n",
      "Epoch 00180: acc improved from 0.67012 to 0.67426, saving model to weights-improvement-180-0.67.hdf5\n",
      "Epoch 181/300\n",
      "2898/2898 [==============================] - 27s 9ms/step - loss: 0.8883 - acc: 0.6905\n",
      "\n",
      "Epoch 00181: acc improved from 0.67426 to 0.69048, saving model to weights-improvement-181-0.69.hdf5\n",
      "Epoch 182/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.8819 - acc: 0.7036\n",
      "\n",
      "Epoch 00182: acc improved from 0.69048 to 0.70359, saving model to weights-improvement-182-0.70.hdf5\n",
      "Epoch 183/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.9020 - acc: 0.6760\n",
      "\n",
      "Epoch 00183: acc did not improve from 0.70359\n",
      "Epoch 184/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.8882 - acc: 0.6784\n",
      "\n",
      "Epoch 00184: acc did not improve from 0.70359\n",
      "Epoch 185/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.8844 - acc: 0.6856\n",
      "\n",
      "Epoch 00185: acc did not improve from 0.70359\n",
      "Epoch 186/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.8727 - acc: 0.6901\n",
      "\n",
      "Epoch 00186: acc did not improve from 0.70359\n",
      "Epoch 187/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 0.8643 - acc: 0.6967\n",
      "\n",
      "Epoch 00187: acc did not improve from 0.70359\n",
      "Epoch 188/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.8544 - acc: 0.6957\n",
      "\n",
      "Epoch 00188: acc did not improve from 0.70359\n",
      "Epoch 189/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.8477 - acc: 0.7026\n",
      "\n",
      "Epoch 00189: acc did not improve from 0.70359\n",
      "Epoch 190/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.8503 - acc: 0.6991\n",
      "\n",
      "Epoch 00190: acc did not improve from 0.70359\n",
      "Epoch 191/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.8425 - acc: 0.7133\n",
      "\n",
      "Epoch 00191: acc improved from 0.70359 to 0.71325, saving model to weights-improvement-191-0.71.hdf5\n",
      "Epoch 192/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.8346 - acc: 0.7115\n",
      "\n",
      "Epoch 00192: acc did not improve from 0.71325\n",
      "Epoch 193/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.8209 - acc: 0.7101\n",
      "\n",
      "Epoch 00193: acc did not improve from 0.71325\n",
      "Epoch 194/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.8222 - acc: 0.7226\n",
      "\n",
      "Epoch 00194: acc improved from 0.71325 to 0.72257, saving model to weights-improvement-194-0.72.hdf5\n",
      "Epoch 195/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.8055 - acc: 0.7239\n",
      "\n",
      "Epoch 00195: acc improved from 0.72257 to 0.72395, saving model to weights-improvement-195-0.72.hdf5\n",
      "Epoch 196/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.7894 - acc: 0.7260\n",
      "\n",
      "Epoch 00196: acc improved from 0.72395 to 0.72602, saving model to weights-improvement-196-0.73.hdf5\n",
      "Epoch 197/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.7933 - acc: 0.7239\n",
      "\n",
      "Epoch 00197: acc did not improve from 0.72602\n",
      "Epoch 198/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.7896 - acc: 0.7177\n",
      "\n",
      "Epoch 00198: acc did not improve from 0.72602\n",
      "Epoch 199/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.7780 - acc: 0.7329\n",
      "\n",
      "Epoch 00199: acc improved from 0.72602 to 0.73292, saving model to weights-improvement-199-0.73.hdf5\n",
      "Epoch 200/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.7775 - acc: 0.7312\n",
      "\n",
      "Epoch 00200: acc did not improve from 0.73292\n",
      "Epoch 201/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 0.7694 - acc: 0.7350\n",
      "\n",
      "Epoch 00201: acc improved from 0.73292 to 0.73499, saving model to weights-improvement-201-0.73.hdf5\n",
      "Epoch 202/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.7632 - acc: 0.7371\n",
      "\n",
      "Epoch 00202: acc improved from 0.73499 to 0.73706, saving model to weights-improvement-202-0.74.hdf5\n",
      "Epoch 203/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.7470 - acc: 0.7371\n",
      "\n",
      "Epoch 00203: acc did not improve from 0.73706\n",
      "Epoch 204/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.7369 - acc: 0.7374\n",
      "\n",
      "Epoch 00204: acc improved from 0.73706 to 0.73741, saving model to weights-improvement-204-0.74.hdf5\n",
      "Epoch 205/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.7257 - acc: 0.7564\n",
      "\n",
      "Epoch 00205: acc improved from 0.73741 to 0.75638, saving model to weights-improvement-205-0.76.hdf5\n",
      "Epoch 206/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.7188 - acc: 0.7553\n",
      "\n",
      "Epoch 00206: acc did not improve from 0.75638\n",
      "Epoch 207/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.7289 - acc: 0.7536\n",
      "\n",
      "Epoch 00207: acc did not improve from 0.75638\n",
      "Epoch 208/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.7261 - acc: 0.7488\n",
      "\n",
      "Epoch 00208: acc did not improve from 0.75638\n",
      "Epoch 209/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.7059 - acc: 0.7667\n",
      "\n",
      "Epoch 00209: acc improved from 0.75638 to 0.76674, saving model to weights-improvement-209-0.77.hdf5\n",
      "Epoch 210/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.7067 - acc: 0.7585\n",
      "\n",
      "Epoch 00210: acc did not improve from 0.76674\n",
      "Epoch 211/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.6936 - acc: 0.7764\n",
      "\n",
      "Epoch 00211: acc improved from 0.76674 to 0.77640, saving model to weights-improvement-211-0.78.hdf5\n",
      "Epoch 212/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.6857 - acc: 0.7681\n",
      "\n",
      "Epoch 00212: acc did not improve from 0.77640\n",
      "Epoch 213/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.6878 - acc: 0.7578\n",
      "\n",
      "Epoch 00213: acc did not improve from 0.77640\n",
      "Epoch 214/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.6874 - acc: 0.7664\n",
      "\n",
      "Epoch 00214: acc did not improve from 0.77640\n",
      "Epoch 215/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.6819 - acc: 0.7605\n",
      "\n",
      "Epoch 00215: acc did not improve from 0.77640\n",
      "Epoch 216/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.6773 - acc: 0.7688\n",
      "\n",
      "Epoch 00216: acc did not improve from 0.77640\n",
      "Epoch 217/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.6563 - acc: 0.7836\n",
      "\n",
      "Epoch 00217: acc improved from 0.77640 to 0.78364, saving model to weights-improvement-217-0.78.hdf5\n",
      "Epoch 218/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.6407 - acc: 0.7864\n",
      "\n",
      "Epoch 00218: acc improved from 0.78364 to 0.78640, saving model to weights-improvement-218-0.79.hdf5\n",
      "Epoch 219/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.6380 - acc: 0.7912\n",
      "\n",
      "Epoch 00219: acc improved from 0.78640 to 0.79124, saving model to weights-improvement-219-0.79.hdf5\n",
      "Epoch 220/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.6467 - acc: 0.7916\n",
      "\n",
      "Epoch 00220: acc improved from 0.79124 to 0.79158, saving model to weights-improvement-220-0.79.hdf5\n",
      "Epoch 221/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.6288 - acc: 0.7957\n",
      "\n",
      "Epoch 00221: acc improved from 0.79158 to 0.79572, saving model to weights-improvement-221-0.80.hdf5\n",
      "Epoch 222/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.6242 - acc: 0.7961\n",
      "\n",
      "Epoch 00222: acc improved from 0.79572 to 0.79607, saving model to weights-improvement-222-0.80.hdf5\n",
      "Epoch 223/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 0.6234 - acc: 0.7971\n",
      "\n",
      "Epoch 00223: acc improved from 0.79607 to 0.79710, saving model to weights-improvement-223-0.80.hdf5\n",
      "Epoch 224/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.6336 - acc: 0.7961\n",
      "\n",
      "Epoch 00224: acc did not improve from 0.79710\n",
      "Epoch 225/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.6115 - acc: 0.8037\n",
      "\n",
      "Epoch 00225: acc improved from 0.79710 to 0.80366, saving model to weights-improvement-225-0.80.hdf5\n",
      "Epoch 226/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.5952 - acc: 0.8054\n",
      "\n",
      "Epoch 00226: acc improved from 0.80366 to 0.80538, saving model to weights-improvement-226-0.81.hdf5\n",
      "Epoch 227/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.5951 - acc: 0.8009\n",
      "\n",
      "Epoch 00227: acc did not improve from 0.80538\n",
      "Epoch 228/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.5822 - acc: 0.8102\n",
      "\n",
      "Epoch 00228: acc improved from 0.80538 to 0.81021, saving model to weights-improvement-228-0.81.hdf5\n",
      "Epoch 229/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.5638 - acc: 0.8223\n",
      "\n",
      "Epoch 00229: acc improved from 0.81021 to 0.82229, saving model to weights-improvement-229-0.82.hdf5\n",
      "Epoch 230/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.5680 - acc: 0.8123\n",
      "\n",
      "Epoch 00230: acc did not improve from 0.82229\n",
      "Epoch 231/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.6000 - acc: 0.8054\n",
      "\n",
      "Epoch 00231: acc did not improve from 0.82229\n",
      "Epoch 232/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 0.5570 - acc: 0.8223\n",
      "\n",
      "Epoch 00232: acc improved from 0.82229 to 0.82229, saving model to weights-improvement-232-0.82.hdf5\n",
      "Epoch 233/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.5591 - acc: 0.8230\n",
      "\n",
      "Epoch 00233: acc improved from 0.82229 to 0.82298, saving model to weights-improvement-233-0.82.hdf5\n",
      "Epoch 234/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.5600 - acc: 0.8199\n",
      "\n",
      "Epoch 00234: acc did not improve from 0.82298\n",
      "Epoch 235/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.5412 - acc: 0.8347\n",
      "\n",
      "Epoch 00235: acc improved from 0.82298 to 0.83471, saving model to weights-improvement-235-0.83.hdf5\n",
      "Epoch 236/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.5437 - acc: 0.8244\n",
      "\n",
      "Epoch 00236: acc did not improve from 0.83471\n",
      "Epoch 237/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.5313 - acc: 0.8264\n",
      "\n",
      "Epoch 00237: acc did not improve from 0.83471\n",
      "Epoch 238/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.5317 - acc: 0.8285\n",
      "\n",
      "Epoch 00238: acc did not improve from 0.83471\n",
      "Epoch 239/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.5277 - acc: 0.8347\n",
      "\n",
      "Epoch 00239: acc did not improve from 0.83471\n",
      "Epoch 240/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 0.5080 - acc: 0.8464\n",
      "\n",
      "Epoch 00240: acc improved from 0.83471 to 0.84645, saving model to weights-improvement-240-0.85.hdf5\n",
      "Epoch 241/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.5017 - acc: 0.8509\n",
      "\n",
      "Epoch 00241: acc improved from 0.84645 to 0.85093, saving model to weights-improvement-241-0.85.hdf5\n",
      "Epoch 242/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.4949 - acc: 0.8461\n",
      "\n",
      "Epoch 00242: acc did not improve from 0.85093\n",
      "Epoch 243/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.5102 - acc: 0.8340\n",
      "\n",
      "Epoch 00243: acc did not improve from 0.85093\n",
      "Epoch 244/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.4829 - acc: 0.8551\n",
      "\n",
      "Epoch 00244: acc improved from 0.85093 to 0.85507, saving model to weights-improvement-244-0.86.hdf5\n",
      "Epoch 245/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.4790 - acc: 0.8440\n",
      "\n",
      "Epoch 00245: acc did not improve from 0.85507\n",
      "Epoch 246/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.4872 - acc: 0.8458\n",
      "\n",
      "Epoch 00246: acc did not improve from 0.85507\n",
      "Epoch 247/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.4801 - acc: 0.8616\n",
      "\n",
      "Epoch 00247: acc improved from 0.85507 to 0.86163, saving model to weights-improvement-247-0.86.hdf5\n",
      "Epoch 248/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.4601 - acc: 0.8599\n",
      "\n",
      "Epoch 00248: acc did not improve from 0.86163\n",
      "Epoch 249/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.4763 - acc: 0.8544\n",
      "\n",
      "Epoch 00249: acc did not improve from 0.86163\n",
      "Epoch 250/300\n",
      "2898/2898 [==============================] - 27s 9ms/step - loss: 0.4452 - acc: 0.8634\n",
      "\n",
      "Epoch 00250: acc improved from 0.86163 to 0.86335, saving model to weights-improvement-250-0.86.hdf5\n",
      "Epoch 251/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.4579 - acc: 0.8609\n",
      "\n",
      "Epoch 00251: acc did not improve from 0.86335\n",
      "Epoch 252/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.4482 - acc: 0.8665\n",
      "\n",
      "Epoch 00252: acc improved from 0.86335 to 0.86646, saving model to weights-improvement-252-0.87.hdf5\n",
      "Epoch 253/300\n",
      "2898/2898 [==============================] - 31s 11ms/step - loss: 0.4396 - acc: 0.8692\n",
      "\n",
      "Epoch 00253: acc improved from 0.86646 to 0.86922, saving model to weights-improvement-253-0.87.hdf5\n",
      "Epoch 254/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.4377 - acc: 0.8689\n",
      "\n",
      "Epoch 00254: acc did not improve from 0.86922\n",
      "Epoch 255/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.4314 - acc: 0.8682\n",
      "\n",
      "Epoch 00255: acc did not improve from 0.86922\n",
      "Epoch 256/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.4301 - acc: 0.8685\n",
      "\n",
      "Epoch 00256: acc did not improve from 0.86922\n",
      "Epoch 257/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.4270 - acc: 0.8685\n",
      "\n",
      "Epoch 00257: acc did not improve from 0.86922\n",
      "Epoch 258/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.4238 - acc: 0.8782\n",
      "\n",
      "Epoch 00258: acc improved from 0.86922 to 0.87819, saving model to weights-improvement-258-0.88.hdf5\n",
      "Epoch 259/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.4225 - acc: 0.8706\n",
      "\n",
      "Epoch 00259: acc did not improve from 0.87819\n",
      "Epoch 260/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.3959 - acc: 0.8837\n",
      "\n",
      "Epoch 00260: acc improved from 0.87819 to 0.88371, saving model to weights-improvement-260-0.88.hdf5\n",
      "Epoch 261/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.4006 - acc: 0.8858\n",
      "\n",
      "Epoch 00261: acc improved from 0.88371 to 0.88578, saving model to weights-improvement-261-0.89.hdf5\n",
      "Epoch 262/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.3859 - acc: 0.8930\n",
      "\n",
      "Epoch 00262: acc improved from 0.88578 to 0.89303, saving model to weights-improvement-262-0.89.hdf5\n",
      "Epoch 263/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.4128 - acc: 0.8734\n",
      "\n",
      "Epoch 00263: acc did not improve from 0.89303\n",
      "Epoch 264/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.4402 - acc: 0.8803\n",
      "\n",
      "Epoch 00264: acc did not improve from 0.89303\n",
      "Epoch 265/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.3641 - acc: 0.9023\n",
      "\n",
      "Epoch 00265: acc improved from 0.89303 to 0.90235, saving model to weights-improvement-265-0.90.hdf5\n",
      "Epoch 266/300\n",
      "2898/2898 [==============================] - 28s 10ms/step - loss: 0.3671 - acc: 0.9003\n",
      "\n",
      "Epoch 00266: acc did not improve from 0.90235\n",
      "Epoch 267/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.4110 - acc: 0.8685\n",
      "\n",
      "Epoch 00267: acc did not improve from 0.90235\n",
      "Epoch 268/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.3707 - acc: 0.8937\n",
      "\n",
      "Epoch 00268: acc did not improve from 0.90235\n",
      "Epoch 269/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.3917 - acc: 0.8834\n",
      "\n",
      "Epoch 00269: acc did not improve from 0.90235\n",
      "Epoch 270/300\n",
      "2898/2898 [==============================] - 26s 9ms/step - loss: 0.3883 - acc: 0.8830\n",
      "\n",
      "Epoch 00270: acc did not improve from 0.90235\n",
      "Epoch 271/300\n",
      "2898/2898 [==============================] - 24s 8ms/step - loss: 0.3675 - acc: 0.8954\n",
      "\n",
      "Epoch 00271: acc did not improve from 0.90235\n",
      "Epoch 272/300\n",
      "2898/2898 [==============================] - 25s 8ms/step - loss: 0.3546 - acc: 0.8972\n",
      "\n",
      "Epoch 00272: acc did not improve from 0.90235\n",
      "Epoch 273/300\n",
      "2898/2898 [==============================] - 23s 8ms/step - loss: 0.3682 - acc: 0.8889\n",
      "\n",
      "Epoch 00273: acc did not improve from 0.90235\n",
      "Epoch 274/300\n",
      "2898/2898 [==============================] - 25s 9ms/step - loss: 0.3634 - acc: 0.8927\n",
      "\n",
      "Epoch 00274: acc did not improve from 0.90235\n",
      "Epoch 275/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.3437 - acc: 0.9010\n",
      "\n",
      "Epoch 00275: acc did not improve from 0.90235\n",
      "Epoch 276/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.3393 - acc: 0.9037\n",
      "\n",
      "Epoch 00276: acc improved from 0.90235 to 0.90373, saving model to weights-improvement-276-0.90.hdf5\n",
      "Epoch 277/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.3369 - acc: 0.9092\n",
      "\n",
      "Epoch 00277: acc improved from 0.90373 to 0.90925, saving model to weights-improvement-277-0.91.hdf5\n",
      "Epoch 278/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3351 - acc: 0.9048\n",
      "\n",
      "Epoch 00278: acc did not improve from 0.90925\n",
      "Epoch 279/300\n",
      "2898/2898 [==============================] - 20s 7ms/step - loss: 0.3249 - acc: 0.9103\n",
      "\n",
      "Epoch 00279: acc improved from 0.90925 to 0.91028, saving model to weights-improvement-279-0.91.hdf5\n",
      "Epoch 280/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3335 - acc: 0.9068\n",
      "\n",
      "Epoch 00280: acc did not improve from 0.91028\n",
      "Epoch 281/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3290 - acc: 0.9096\n",
      "\n",
      "Epoch 00281: acc did not improve from 0.91028\n",
      "Epoch 282/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3192 - acc: 0.9117\n",
      "\n",
      "Epoch 00282: acc improved from 0.91028 to 0.91166, saving model to weights-improvement-282-0.91.hdf5\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2898/2898 [==============================] - 22s 7ms/step - loss: 0.3261 - acc: 0.9113\n",
      "\n",
      "Epoch 00283: acc did not improve from 0.91166\n",
      "Epoch 284/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3073 - acc: 0.9179\n",
      "\n",
      "Epoch 00284: acc improved from 0.91166 to 0.91787, saving model to weights-improvement-284-0.92.hdf5\n",
      "Epoch 285/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3120 - acc: 0.9117\n",
      "\n",
      "Epoch 00285: acc did not improve from 0.91787\n",
      "Epoch 286/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3035 - acc: 0.9199\n",
      "\n",
      "Epoch 00286: acc improved from 0.91787 to 0.91994, saving model to weights-improvement-286-0.92.hdf5\n",
      "Epoch 287/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3110 - acc: 0.9103\n",
      "\n",
      "Epoch 00287: acc did not improve from 0.91994\n",
      "Epoch 288/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.4734 - acc: 0.8854\n",
      "\n",
      "Epoch 00288: acc did not improve from 0.91994\n",
      "Epoch 289/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3037 - acc: 0.9217\n",
      "\n",
      "Epoch 00289: acc improved from 0.91994 to 0.92167, saving model to weights-improvement-289-0.92.hdf5\n",
      "Epoch 290/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.2911 - acc: 0.9234\n",
      "\n",
      "Epoch 00290: acc improved from 0.92167 to 0.92340, saving model to weights-improvement-290-0.92.hdf5\n",
      "Epoch 291/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.2977 - acc: 0.9165\n",
      "\n",
      "Epoch 00291: acc did not improve from 0.92340\n",
      "Epoch 292/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.2706 - acc: 0.9327\n",
      "\n",
      "Epoch 00292: acc improved from 0.92340 to 0.93271, saving model to weights-improvement-292-0.93.hdf5\n",
      "Epoch 293/300\n",
      "2898/2898 [==============================] - 20s 7ms/step - loss: 0.2818 - acc: 0.9258\n",
      "\n",
      "Epoch 00293: acc did not improve from 0.93271\n",
      "Epoch 294/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.2774 - acc: 0.9268\n",
      "\n",
      "Epoch 00294: acc did not improve from 0.93271\n",
      "Epoch 295/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 0.2834 - acc: 0.9220\n",
      "\n",
      "Epoch 00295: acc did not improve from 0.93271\n",
      "Epoch 296/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.3034 - acc: 0.9137\n",
      "\n",
      "Epoch 00296: acc did not improve from 0.93271\n",
      "Epoch 297/300\n",
      "2898/2898 [==============================] - 22s 7ms/step - loss: 0.2773 - acc: 0.9255\n",
      "\n",
      "Epoch 00297: acc did not improve from 0.93271\n",
      "Epoch 298/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.2600 - acc: 0.9337\n",
      "\n",
      "Epoch 00298: acc improved from 0.93271 to 0.93375, saving model to weights-improvement-298-0.93.hdf5\n",
      "Epoch 299/300\n",
      "2898/2898 [==============================] - 22s 8ms/step - loss: 0.2731 - acc: 0.9282\n",
      "\n",
      "Epoch 00299: acc did not improve from 0.93375\n",
      "Epoch 300/300\n",
      "2898/2898 [==============================] - 21s 7ms/step - loss: 0.2612 - acc: 0.9355\n",
      "\n",
      "Epoch 00300: acc improved from 0.93375 to 0.93547, saving model to weights-improvement-300-0.94.hdf5\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(sequence_length, vocab_length)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(vocab_length))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "\n",
    "if saveModel:\n",
    "    filepath=\"weights-improvement-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    history = model.fit(input_notes, output_notes, batch_size=128, nb_epoch=training_rounds, callbacks=callbacks_list)\n",
    "else:\n",
    "    history = model.fit(input_notes, output_notes, batch_size=128, nb_epoch=training_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Model's Results\n",
    "The models accuracy can be seen here increasing, as it learns the sequences over the course of 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu4AAAIqCAYAAAB7ZM9oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xm83NP9+PHXySYRgiS2oEgIoakt1C6kTe1LVe2176W+LbUXRctP1dbSoqGopahaqvbYWyp2TcQWuyQSYons5/fHmduZe+/cNZP5zPJ6Ph7z+JzPOZ/PZ97TMvftzFlCjBFJkiRJla1L1gFIkiRJapuJuyRJklQFTNwlSZKkKmDiLkmSJFUBE3dJkiSpCpi4S5IkSVXAxF2SJEmqAibukiRJUhUwcZckSZKqgIm7JEmSVAVM3CVJkqQqYOIuSZIkVQETd0mSJKkKmLhLkiRJVcDEXRUlhLBzCCHmXvdnHY8kKVshhGtyfxMeyToWKWsm7qo0+xWUR4QQls8sEkmSpApi4q6KEULoB2wHTAduIP3zuU+mQUmSJFUIE3dVkr2A7sAdwB9zdfu1fLkkSVL9MHFXJWlI0v8CPA68C6weQtigtZtCCL1DCMeFEJ4KIUwNIcwIIbwVQrgzhLB3CKF7kXtCCGH3EMI/QggfhxBmhhA+CCE8FkL4v1zvf8O1KzWMu28lhuG5ayYUaZuQaxseQlguhHBZLr6ZIYQXCq5bNoRwRC6m10MI00MIn4cQng8hnBlCWLyN/x3a9ZlCCJvn4plZ+DmLPG9gCGFe7trVWntvSao0IYRBIYQ/5r5vZ4QQPs19Hx4cQujawj1dQgj7hxBGhxCmhBBmhxAmhxBeDSGMCiFsXeSelUMIl4cQxocQvs59d78TQngkhHBSCKH/gv+0qhfdsg5AAgghrAmsB0wB7o8xxhDCjcAJpIT+mRbuWwP4B7BSrmoO8CWwcu61A/AkMKHgnsWAW4Hv5KoiMA1YBhgAbAZ8ClxToo/XYDBwC9CfNBxodpP2S4FdC84/A/oAa+dee4cQhscY32/64I58phjjYyGE8bl49sq9bzEHAAF4Msb4Wsc+qiRlJ4SwPen7tmeuahrQm/RduBmwewhh5xjjV01uvY70vUjBfX1I39tr5F73FrzPusAjwKK5qtnAV8A3cq8tgOcL75Hmhz3uqhQNve1/jTE2JLR/yR33CCH0aHpDCKEv6ctwJeBtYGegd4xxCdIX7WbA1aRkvtBfSAnu18BPgL65e3oBQ4FfkpLcUrsA+AjYJMbYO8a4CPCDgvbXgVOBNYFeuZh6AsOB/wCDyA8haqqjn+lPueMBxR4WQuhC/v+TUe3/iJKUrRDCIOAm0vfno8DqMcbFScn1YcBM0vflxU3u25yUtM8D/g/ok7uvJ6kDZH/giSZv95vcc58G1o0x9sh99/YG1gcuIiX/UkmEGFv89V8qi9xPlu8BywKbxRifKGh7iZR4/iDGeFuT+/4fcDzwCbB2jPGDdrzXtqQe+ghsG2NssxckhLAS6T8MiDGGFq4ZDowG3okxrtSkbQKwIqkHffUY48S23rPI8/sC44AlgYExxrcL2jrzmZYC3ifNKVg7xvhik/aRwH2kXy+WjTF+2dGYJakUQgjXkDoSHo0xDm/H9X8CDgTeBL4VY5zepP1QUidIBAbHGN/I1f8cOA+4N8a4TTtjm07qINkwxvh0ez+T1Fn2uKsSjCQl7e+QhrUUauh1LzZJdd/c8TftSdpzfpQ73teeBLfEru1M0g4QY5wKPJU73ahJc4c/U4xxEnBX7vTAIpc09MTfYtIuqVqEEAL5IYcXNk3ac64CPiANBSz81fPz3HGp3K+O7dFwz7IdjVXqDBN3VYKGpPzG2PwnoBtJvSLbhBCWbKjM9YIvkzu9pwPvtWEn7imVf7V1QQhhg9wEqHEhhC9DfjOqCOyUu2xAk9s6+5muyh33LhyKlJsEu3Pu9E/N7pKkyjUQWCxXHl3sghjjPNK4dIB1C5oeBGbl6h4JIewTQmj6fdtUw/futSGEc0MIG4YiCyJIpWLirkzlJlU2JKQ3NG2PMb5LWmGmG40nDC1dUH63A2/ZcF9H7imVya01hhCOA/5N6u1ejTSu8lNgYu41I3dp7ya3dvYz3UcaotSPNIm3wd65934txtj0FxBJqmRLFpRb+yW2YZL//67PDZk5gjRXaDPSRNUPQghv51aNWafIc44n/Rq6KGkxhX8Bn4cQHs6tEtar8x9Fas7EXVnbnfys/5cKe5gLepo3z7UXDpcpOta8ws1tqSG3qs55pM/1O9IE1YVijH1jjMvEGJchrRoDJfrsuV6nhomnhZNUG8pXl+J9JCkjC3X0hhjjKNKKZMeS9hSZQloA4XBgTAjh5CbXTwE2Bb4LXEJaQaYHsCVwGfBKcAdwlZCJu7LWkQ2W1gkhDM2VPy6oX7EDz2gYY96Re/63Kk0IoWcL1yzWQn177Ur69/G+GOPRMcb/xhibJvpLF7kPOveZGowiraCwdW4d+aGkZTnnAtd24nmSlKXCXzZb+05sSKab/RIaY5wYY7w4xrgzqUd+A+B2UqfJWSGEbzW5PsYYH4wx/iTGuC5p6cjDgKmkoTsXdvrTSE2YuCszIYRVgI1zp2sDS7TyaphIuR9AjHEC+eR92w687b87cc9nBeWWek7W78Dziml47vPFGkMIvcmPZW+qM58J+N9QpAeArqRJrg0TVf8ZY/yoo8+TpIy9Rf47e8tiF+Qmng7PnT7X2sNySfl/gN1Iw2u6kHrYW7vn0xjjFUBD7/wW7YpcagcTd2Wpobf9xRjjizHGz1p6kTbSgDSRsmHHu+tyx5+FEJZr53s29CKPLLYDXjG5VVUm5E53atqe23304Ha+f0sa1vkd2kL7KeQ3+Giqw5+piStzxwNJ49vBSamSqlBugYO/5U5/EkJYuMhlBwPLkRY+aBiCSLH9QgqeO5f8pnkL5a7vEkJobSPLrwuvl0rBxF2ZyC3Z1bCc499auzbnLtKX5jLA93J155EmH/UHHg8h7NjwxRtCWCSEMDyEcFOT8YX/zL0CcFsI4ejcKiqEEHqEEIaGEC4IIexMY3/NHU/NvU+33D0bklYiaPELv50eyB23CyGc3PDHJoSwZAjhfOAk0ljLYjr7mRrcCUwi7aS6ZK78j/n8PJJUat1DCP3beHUHfkXavXQA8I8QwmoAIYSFQgiHkMaiA/ypYQ33nF+FEG4NIeyc2zuD3H1LhxAuIY19j+S/r/sAb4QQTsl9z3bNXd8lhDACOCd33X0L5n8O1aUYoy9fZX+RfsKMudea7bzn3tz1NxfUDSWtjNLwrFmklVhiwWulJs9ZnLQUWEP7XNJYxLkFdfs3uWcJ0mYeDe0zSJsTRdL68/vkyhOKxD0h1za8jc93W8Hz5+Vimpc7/xNwTa58RpF7O/yZmtx/fsF1v8n6nw9fvnz5angVfPe15zU8d88OpB7vhvpPc38fGs4fJO20Xfg+FzV51jTSOu2FdScXXL94k7ZZpA6WOQV1bwLLZ/2/oa/aednjrqw0DJMZH2N8tZ33NOyculNDj3KM8WXSCiynAs+Svqh7ksY5/h3Yk/yyX+Tu+QzYKhfDg6QEdxHgI9L22MeSeqEL7/mUNB7/CuBD0q9VU4BLSWv+NnqPTtodOBEYS/p1IZA2pNovxnhQazd25jM1Ufirx6gWr5KkKhBjvIvUsXMlqfNkYWA68ARwKPC9GONXTW67EDiGtJrMeNJ38EKkzqGbgc1jjL8quP5zYHtSwv8MaaLroqTe/v+QhjiuHWMsxd8HCYAQY9P9biTVmxDCKcDZwNMxxpYmwUqSpAzZ4y7Vudy4zIbJtVdkGYskSWqZibtUx3KThH9B2mBkInBjpgFJkqQWtbaMkaQalVsN5ybSpNs+ueqTY4xft3yXJEnKkj3uUn3qSdpVsBcwDjg0pq2+JUlShXJyqiRJklQF7HGXJEmSqoCJuyRJklQFTNwlSZKkKmDiLkmSJFUBE3dJkiSpCtTVOu4hhLdJa1ZPyDgUSeqMlYDPY4wrZx1Iufi9LamKrUSJv7PrKnEH+vTq1avvkCFD+mYdiCR11NixY/n667rbI8vvbUlVaUF8Z9db4j5hyJAhfceMGZN1HJLUYeuttx7PPffchKzjKDO/tyVVpQXxne0Yd0mSJKkKmLhLkiRJVcDEXZIkSaoCJu6SJElSFTBxlyRJkqqAibskSZJUBUzcJUmSpCpg4i5JkiRVARN3SZIkqQqYuEuSJElVwMRdkiRJqgIm7pIkSVIVMHGXJEmSqoCJuyRJklQFTNwlSZKkKmDiLkll9Pnn8OyzMG9e1pHUuDlz4Msvs45CkkrKxF2SymTyZLj8clh/fRgwAH7966wjqkGffgo9ekD37rDCCllHI0klZeIuSSX2j3/AdtvB3/6Wrxs7NuWRJ56YzidOhLlzs4mvpvXsCbNnp/L06dnGIkkl1i3rACSplsQIBx4IkybBPffAtGnQpw9ceCHMnNn42m23zSbGmtazZ748a1b6r6OuXbOLR5JKyB53SSqhiRNT0t7g8stTMv/gg82vXXvt8sVVN0KAhRfOn3/9dXaxSFKJ2eMuSSX09tuNz088MQ2TeeedxvW77AJd7DpZMHr1yg+TmT4dFlkk23gkqUT8syFJJfLSS8WHv/z5z41XkenZE049tXxx1Z3CHnfHuUuqISbukjQfpk9PozEefBA23BA++6z16/fbDz7+GNZdtzzx1SWHykiqUQ6VkaRO+OwzeOwx2Gsv6NYN+vZtniMus0xK0gttuikstlj54qxLvXrly/a4S6ohJu6S1EFvvQVrrdV4f59p05pfd/nlsPfejXPHb31rwcdX9xwqI6lGOVRGkjrovPPatynnqqvCsGGN69Zcc8HEpAIOlZFUo0zcJakDnnwSrrii7etWXRVWWw0GDWpc37v3golLBRwqI6lGOVRGklrw9ddw333w8stw551pbPpDD7V93513prHs3brBT3+aX1Xm0EMXfMzCoTKSapaJuyS1YL/94JZbOnZPz56www75829+E+64Iy0VefjhpY1PLXCojKQa5VAZSSrirbdaT9qPOQauvhpWWKFxfZ8+za/dfns4+eS08ozKwKEykmqUPe6S6spXX6VlHDfdFBZdtOXrRo0qXt+vH7zwAiy/fDqfMgWOOy7f7lKPFcChMpJqlD3ukurKbrul3U1XWw3GjSt+zfPPw/nnN68/5BB44ol80g6w1FKNrzFxrwAOlZFUo+xxl1Q35syBe+9N5Y8+goMOSqvEFLYD/PKXMGtWKi+9dJpguv32sMYazZ+55JKNz03cK4BDZSTVKBN3SXVj0iSIMX/+r3+l1V66dIG77kqrvsyaBVOn5q+56y5Yf/2Wn2mPewVyqIykGmXiLqnmxQivvQYTJzavP/lk+N73YMcdm983YEDzDZSaatrjXmxyqsrMoTKSapRj3CXVvAsvhCFDYPjw5m3nnQdbbVX8vi23hBBaf7aJewVyqIykGmXiLqmmxQg/+1nn7t1yy7av6dmz+fspYw6VkVSjTNwl1bSxYzt/7267dfyemTM7/34qEYfKSKpRJu6Sato113Tuvssv79ywFxP3CmCPu6Qa5eRUSTXr0UfhN79p//XLLAOnnpoS9n326dx7Dh3auftUQo5xl1SjTNwl1axRozo25nyddeCoozr+Pg89BD/4Aay8cufuV4k5VEZSjTJxl1Rz5syBM8+Ea69t/z09esCxx3bu/bbaKi012a1b26vQqAwKE/evvsouDkkqMce4S6o5f/kLnH12+6+/6SaYNg1Gjuz8e3bvbtJeMRZfPF/+5BOX+pFUM0zcJdWcc85pfF6YxxUzeHDzZR1VxRZbLN/r/vXX8Nln2cYjSSVi4i6p5jSdj9i3b+PzjTZqfN50EyVVuRBg+eXz5x98kF0sklRCJu6Sqt5NN8EOO8ARR8Avf9k8TwsBDj00lfv3h5NPbtxu4l6DllsuX37//ezikKQScnKqpKr2wAOw116tD2M+9VTYc0/43vdg7bVh8uTG7QsttGBjVAYKE3d73CXVCBN3SVXrk0/ggANaTtp79Uqry+yzT1rx5fvfT/UDBqRe9smT529CqiqYQ2Uk1SATd0lVY968tKnSkkvCvffC8cc3bj/wQPjyy7SR0iqrwMEHN96Lp0HPnvDgg3D//aknXjXIoTKSapCJu6SqMWoUHHJI8baf/xzOO6/9z/rWt9JLNcoed0k1yMmpkqrG3Xe33Lb//mULQ9XAMe6SapA97pIq3gMPwKRJ8NprxdvPOw+GDClvTKpwJu6SapCJu6SK9vTTrU8g/eUv0zAZqZGll4auXWHu3DSLecYMd9mSVPVM3CVVpLvvhocegqeeav26rbcuTzyqMl27wrLL5iemfvghDByYbUySNJ9M3CVVnJdfhp12SqvIFBMCbLMNbLIJrL9+eWNTFVluuXzi/sEHJu6Sqp6Ju6SKc+65LSftkJL6228vXzyqUssvn8ZagUtCSqoJriojqaJ89hncfHPr19hxqnZxgqqkGmPiLqmivPRSmk/Ymk02KU8sqnIm7pJqjIm7pIry0kuttx98MOyyS3liUZUr3ITJoTKSaoCJu6SK0lri/vTTcMUVaXKqKlcIYd8QQsy9Ds4skAED8uWPP84sDEkqFRN3SZn68ku46qr8so+tJe4bbGDSXulCCCsAlwJfZh0L/frly1OmZBeHJJWIibukTJ1+OhxyCAwfDuPGwSuv5NuGDs0sLHVCCCEAVwNTgD9kHI6Ju6SaY+IuKVO//W06zp4NO+4IX32VzldYIe2K2mDvvcsfmzrsGGAr4ADgq4xjgb598+WpUyHG7GKRpBIwcZeUmaZ51Ouv58s/+EFar/3UU2G33eCss8obmzomhDAEOBe4OMb4WNbxANCzJyy8cCrPmQNffJFtPJI0n9yASVJmJk5suW333dN4dhP2yhdC6AZcB7wLnNzJZ4xpoWn1zsYFpOEy06en8pQp0KfPfD1OkrJkj7uksmroZZ89G667rvg13/52moiqqvELYB1g/xjj11kH00jhOPepU7OLQ5JKwB53SWUxZw5svz288EIau/6rX8E77zS/bpVV4K67XD2mWoQQNiD1sl8QY/xXZ58TY1yvheePAdbt7HMbjXN3gqqkKmfiLqksbr0V7rsvlQ87rPg13/kO3Hgj9O9fvrjUeQVDZMYDp2UcTnGuLCOphjhURlJZPPlk6+3XXAMPPGDSXmUWAQYDQ4AZBZsuReD03DVX5uouyiRCh8pIqiH2uEsqi08+abltrbVgl13KF4tKZibwpxba1iWNe38CeA3o9DCa+eJQGUk1xMRdUlkUbqxU6PXXYdAgx7RXo9xE1IOLtYUQziAl7n+OMV5VzrgacaiMpBriUBlJC9ysWWlX1KZCSBstmbRrgTFxl1RDSpa4hxCWDyGMCiF8GEKYGUKYEEK4KISwRAefs2kI4Y7c/TNCCO+GEO4JIWxdqlgllddrr6VVZZpaZhlYaKHyx6M6suyy+fJ772UXhySVQEkS9xDCIGAMaZvrZ4ALgbeAnwD/CiH0a+X2wuccATwOjMgdLwQeBbYA/hlCOKUU8Uoqn+efhx12KN7mXMHaFWM8I8YYMh0mA2l90QaFW/NKUhUqVY/7ZcBSwDExxp1jjCfGGLciJd6rAee09YAQQnfg18AMYL0Y474xxpNijPsCw0iToE4JIdg/J1WJm29OGykVW68dUo+7tEB94xvQLTed66OP4Kuvso1HkubDfCfuIYSBwEhgAvD7Js2nA18B+4YQerfxqL7AYsD4GONrhQ0xxrGkdYJ7kZYfk1ThZs1K67U3HSJz9tn58umnIy1Y3brBwIH58zfeyC4WSZpPpVhVZqvc8f4Y47zChhjjFyGEJ0mJ/YbAQ608ZxIwGRgcQlg1xvi/3zRDCIOBVYEXYoxtzi7K7bRXzOpt3SupNJ58EqZNa17/05/CFlvA55/D1s5cUTmssgqMH5/Kb7yR1h+VpCpUisR9tdxxfAvtr5MS98G0krjHGGMI4SjgemBMCOF24ENgOWAX4FVgjxLEK2kBiRGeeQbuugvOKTJAbuedoVcv2HTT8semOuY4d0k1ohSJ+2K5Y5G+tUb1i7f1oBjjLSGED4EbgR8VNE0EriZNeG1TjHG9YvW5nvh12/MMSR13wQVw/PHN6y+6CJZeGrbbrvwxSay6ar5s4i6pipVjHfeGFZpjmxeGsA/wIGlFmSHAwrnjQ8DvgJsWUIyS5tOjjxZP2pdYAg48EPbYAxZdtPxxSY163B3jLqmKlaLHvaFHfbEW2vs0ua6o3Dj2UcBLwL4F4+XHhRD2JQ3J2S2EMDzG+Mj8hSyplO64Iw2DKfR//wd9+qSlIE3YlSl73CXViFIk7g0rwAxuob3hG7OlMfANRgLdgUeLTHKdF0J4DFgv93qkc6FKKrUY4Ze/bFz317/CbrtlE4/UzIorptVl5szJLwnZu62FziSp8pRiqMzo3HFkCKHR80IIiwKbAF8D/27jOQ3rsy/ZQntD/azOBClpwXj4YXjuufz5pZeatKvCdOsGK6+cP3e4jKQqNd+Je4zxTeB+YCXgqCbNZwK9gWtjjP/b9SKEsHoIoenSjI/njj8IIXyrsCGEsDbwA9I4+YfnN2ZJpTFtGuy3X/784IPhxz/OLh6pRY5zl1QDSjFUBuBI4CngkhDCCGAs8G1gS9IQmVOaXD82d2yYuEqM8ZkQwtXAAcB/cstBvkP6D4KdgR7ARTHGV0sUs6T5dPvt8MEHqbz44vCLX2Qbj9SiVVeFf/4zlR3nLqlKlSRxjzG+GUIYBvwS2BrYFvgIuAQ4M8Y4tZ2POgh4DNgf+B6wKPA58ARwZYzRVWWkCjJuXL58yCGwwgrZxSK1atCgfPntt7OLQ5LmQ6l63IkxvkfqLW/PtaGF+ghck3tJqiCPP57Gr++1V34FmcIRB9/6VvH7pIqw4or58jvvZBeHJM2HkiXukmrbQQelEQa33AJTpkDfvo0T98IV96SKs9JK+fKECVlFIUnzpRwbMEmqcl9/3XhY8KOPpmUgCxP3wrl/UsVp2uMe29wTUJIqjom7pDa9917j88ceg4kT03LYkCam9u1b/rikdlt8cVgst0/gjBkwaVK28UhSJzhURlKrvvgCzjyzcd3f/gb9+uXPV1kFQtGZK1IFWWklePHFVJ4wAZZeOstoJKnD7HGX1Kqf/QxuuKFx3bvvwmmn5c+HDClvTFKnFI5zd4KqpCpk4i6pVVde2fY1W2yx4OOQ5lvhOHcnqEqqQibuklrU3vl7W265YOOQSsIed0lVzsRdUosmT27fdSuvvGDjkErCHndJVc7JqZIamTwZ9twzLQG50UZtX3/OOU5MVZWwx11SlTNxl9TINdfAQw+l8lNPNW7baCN4//20POSwYXDddbD66mUPUeqcppswxeh/dUqqKibukhop3FSp0G67wc03w9tvw+jRsMMOsNRS5Y1Nmi9LLAGLLAJffpk2IZgyBfr3zzoqSWo3E3dJjbz/fvH6ddZJnZMDB6aXVHVCSL3ur7ySzt95x8RdUlVxcqqkRlpK3O1dV00onKD69tvZxSFJnWDiLqmRwsR9773TsVs3+O53s4lHKqlVVsmXX3stuzgkqRMcKiPpf6ZPh6lTU7l7dxg1CnbeGQYPhm98I9vYpJL45jfz5Zdfzi4OSeoEE3dJ/1PY277cctCjB/zgB9nFI5VcYeLeMNZdkqqEQ2UkAfDRR2lN9gbLL59dLNICs+aa+fJrr8GsWdnFIkkdZOIuibvvTottXHttvs7EXTVp0UXz67nPmQPjx2cajiR1hIm7VMfGjYPDD09rsjfteNx882xikha4oUPz5eeeyy4OSeogE3epTs2dC9tsA3/8Y76uSxc4+GC48UY49NDsYpMWqGHD8uVnnskuDknqICenSnXq3XfTru+FnngCNtook3Ck8tlgg3zZxF1SFTFxl+rM55/DLbekXd8LHXaYSbvqRGHi/sILMGMG9OyZXTyS1E4m7lIdeffdtJFS0/l4m24Kl12WTUxS2fXtmzZieuMNmD07ree+/vpZRyVJbXKMu1QnnngiLWFdbBGNkSPT+HapbhROUHUHVUlVwj/VUp248EL44ovibYW7wEt1YfDgfPn117OLQ5I6wMRdqhOFu7sPGdK4bdCg8sYiZW7VVfNlE3dJVcLEXaoDM2bAm2+mcpcucOedjdtN3FV3Cnvc3YRJUpUwcZdq2PTpsMceaSjMvHmpbuDAdH7EEel8772hX7/sYpQy0bTHPcbsYpGkdjJxl2rYddfBzTfDBx/k69ZcMx0vuwymTIHrr88mNilTSy8NiyySyp9/DpMmZRuPJLWDibtUw158sXldQ+IOaVU8qS6F0LjX/a23sotFktrJxF2qYcXm3H33u+WPQ6pIK6+cL7/9dnZxSFI7mbhLVWzSJDj7bLj//uZtMaZNIRucckqalDp8eNnCkypbYeJuj7ukKuDOqVIVO+64NI69WzeYMAGWWy7Vf/EFrLMOfPJJOu/aFU4/Hbp3zyxUqfLY4y6pytjjLlWx665Lxzlz4K678vU33JBf/hFgoYVM2qVmBg7Ml03cJVUBE3epSjXdBbVXr3R8+mk4/PDGbeusU56YpKpij7ukKmPiLlWpceMan0+bBpMnwyabNL92jz3KE5NUVVZaKV9+912YPTuzUCSpPUzcpSo1dmzj808+gb//HebOzdeFAA89BEcdVd7YpKrQs2d+Ysi8eU5QlVTxTNylKtU0cZ8yBW6/vXHdgw/CVlulBF5SEWuskS//97/ZxSFJ7WDiLlWppkNlXn01JeoNJkxISbukVhTuSPbqq9nFIUnt4HKQUpVq+qv+o4/myxttBCuuWN54pKpkj7ukKmKPu1SFYmx9EYzjjy9fLFJVs8ddUhUxcZeq0NSpzZeDbLDCCrDTTuWNR6paQ4bky6+9ljZFkKQKZeIuVaHWetu33x66+G+21D5LLAHLLpvKM2e6soykiuafd6kKtZa4b7tt+eKQakLhcBnHuUuqYCbuUhVqLXHfcsvyxSHVBCeoSqoSJu5SFXr++eZ1IcAdd0Dv3uXUAEmSAAAgAElEQVSPR6pqTlCVVCVcDlKqMq+/Drfckj//299SrrHVVrDxxtnFJVUte9wlVQkTd6nKXH89zJ2byiNGwC67pJekTirscR87Nv0L1rVrdvFIUgscKiNVmfffz5d32y27OKSascQSsMwyqTxzZtp2WJIqkIm7VGWmTMmX+/fPLg6pphSu5+5wGUkVysRdqjKffJIvm7hLJVI4zn3s2OzikKRWOMZdqnD//Cfcdx889xxMnw5jxuTb+vXLLi6pptjjLqkKmLhLFeyjj2DnnWHWrOLt9rhLJVLY4+6SkJIqlENlpAr25JMtJ+0AffuWLxappg0dmi+/9BLMmJFdLJLUAhN3qYK98ELLbYsuCj16lC8Wqab17w+DB6fyrFlpbJokVRgTd6mCtZY7OExGKrHCHcyefDK7OCSpBSbuUgV7/vl8+YADGrf16VPeWKSaV5i4P/VUdnFIUgtM3KUK9dFH8PHHqdy7N1x5ZeP2zz4rf0xSTdtkk3z5qacgxuxikaQiTNylCjR1auPe9rXWar4D+8SJ5Y1Jqnmrrw6LL57KkybBm29mG48kNWHiLlWI996DI46AENL67Nttl29bZ510XH75fN2AAeWNT6p5XbrARhvlzx0uI6nCmLhLFeK00+APfyjetu666Xjjjfm6Sy9d8DFJdadwuIwTVCVVGDdgkirEiy+23NbQ477ppmmJyNmzYdiw8sQl1ZUNN8yXC7cplqQKYOIuVYgPPihe37MnrLlm/nyttcoTj1SX1l47X37lFZgzB7r5p1JSZXCojFQBZs6EyZPz57165cs//7kbLUll069ffjLJzJkwfny28UhSARN3KSPTpqWhL0OHNh5Ku+yycPXVsN56cN55cMYZmYUo1afCn7Va275YksrMxF3KwO23Q9++KWF/5RXYccd823LLwe67w7PPpt72ELKLU2pLCOG8EMJDIYT3QghfhxCmhhCeDyGcHkLol3V8nVI4XKa1ySeSVGYm7lKZvfwy7LorzJuXr/vqq3x5ueXKH5M0H/4P6A08AFwM/AWYA5wBvBRCWCG70DqpsMfdxF1SBXHGjVRmF17Y+oaMJu6qMn1ijDOaVoYQzgFOBk4Cjix7VPPDoTKSKpQ97lKZvfde6+19+pQnDqkUiiXtOX/NHVctVywlM2gQ9O6dyhMnwscfZxuPJOWYuEtlNG8ePPdc69esvnp5YpEWsB1yx5cyjaIzunZNs8YbOFxGUoVwqIxURuPHw9SpLbevuCLssEPL7VKlCiEcBywCLAYMAzYlJe3ntvP+lnY7yuY/ZddaC/7971R+8UX43vcyCUOSCpm4S2Xy5puw337F2773PRg1Cvr3d812Va3jgKULzu8F9o8xTm7h+spWuLJMWz+TSVKZmLhLC9inn8Ldd8OBB6ZNGJv6yU/goovKH5dUSjHGZQBCCEsDG5N62p8PIWwfY2wz840xrlesPtcTv24pY22XYcPy5WefLfvbS1IxJRvjHkJYPoQwKoTwYQhhZghhQgjhohDCEp141tAQwrW5dYFnhhAmhRAeDSH8qFTxSuWy997wox81T9o33hgOPxxOOimbuKQFIcY4McZ4OzAS6Adcm3FInTN0KHTvnspvvpn+C1ySMlaSxD2EMAgYAxwAPANcCLwF/AT4V0c24Qgh7A88D+wMPA5cANwKBGDbUsQrlcvkyfDPfxZvu/lmuPxyWHrp4u1SNYsxvgP8F1gzhNA/63g6bKGF4Fvfyp87XEZSBSjVUJnLgKWAY2KMlzZUhhB+S9qc4xzg8LYeEkLYELgKeAXYOsb4cZP27iWKVyqL0aOL14fgeu2qCwNyx7mZRtFZ660HY3JzZp9+GkaMyDYeSXVvvnvcQwgDST+JTgB+36T5dOArYN8QQu92PO7/AV2BfZom7QAxxtnzF61UXg8+WLz+4otT8i5VsxDC6iGEZYrUd8ltwLQU8FSMsTrHmWy0Ub78xBPZxSFJOaXocd8qd7w/xjivsCHG+EUI4UlSYr8h8FBLDwkhLA9sBjwLvBpC2BJYD4jAC8Dops+XKt2//tW87sgj4eijyx+LtABsDZwfQngMeBOYQlpZZgtgIPAxcEh24c2nzTbLl598EubOTWu8S1JGSpG4r5Y7jm+h/XVS4j6YVhJ3YP2C6x8GhjdpfzmE8P0Y4xttBVRx6wGrbhXbJXXAgOZ1UpV6ELgC2ARYC1ic9CvreOA64JIYYys7F1S4gQPTv7Affgiffw4vvQTrrJN1VJLqWCkmpy6WO05rob2hfvE2nrNU7vhDYAjw/dyzVyH9ARgK/COE4CrXqnizZ8NNN8G0Iv9WLLVU8zqpGsUYX4kxHhVjXDvG2D/G2C3GuFiMcf0Y4xlVnbRDGs9W2Ov+2GPZxSJJlHA5yFY0jOSNbVzXteB4cIzx9hjj5zHGN4H9SENoBgO7tvWGMcb1ir2AcZ38DFKHXHAB7Lln8TYTd6mKbL55vmziLiljpUjcG/oUF2uhvU+T61rSMHlpJnBPYUOMMQJ35E436GiAUrm1tja7ibtURQoT98cfh9hWH5QkLTilSNxfyx0Ht9C+au7Y0hj4ps/5ooVJqA2Jfa8OxCZVHBN3qYqssQYskdtHcPJkGOcPt5KyU4rEvWGl6pEhhEbPCyEsSpq09DXw7zae8xLwCdA/t2V2U9/MHSd0PlRpwZvXxtpHSy5ZnjgklUCXLo3Hud98c3axSKp7852458ag3w+sBBzVpPlMoDdwbYzxq4bK3Nq/jVZ4iTHOAf6YO/1/hf8REEIYCuwPzCHtoipVrHffbbltxAjo06fldkkVaK+98uUrrkizzyUpA6XaOfVI4CngkhDCCGAs8G1gS9IQmVOaXD82d2y6Bc2vgBHAj4ChIYRHgCVJE1J7Aj9rz3KQUlZeeQWGDm1ef+65sOWWriQnVaVddoFll4WPPkqv22+HH/4w66gk1aGSrCqT63UfBlxDSth/BgwCLgE2ijFOaedzppMS9zOBhUk9+DuS/qNg2xjjb0sRr7Sg/LaFf0KHDIENNoDu3csbj6QS6NEDDj00f/77ppuES1J5lKrHnRjje8AB7by2xc3ec8n7GbmXVPFihOOOg7Fj4Z//bN6+9daw3Xblj0tSCR16KJxzDsyZk5aFfOuttEGTJJVROdZxl2ra3XennvZiSfsJJ6R6d0mXqtyAAbDVVvnz//wnu1gk1S0Td2k+/e1vxeu7doX99itvLJIWoHXXzZeffz67OCTVLRN3aT7ECI8+2rx+5ZXhtdfS2HZJNaJwdrmJu6QMmLhL8+HNN+Htt5vXn3oqDBpU/ngkLUBNE3d3UZVUZibuUifMmwcPPwwHHZSv22QTuOEGuPVW2H//zEKTtKAMGgSLLprKkyfDM89kG4+kumPiLnXCXnulzZQeeyxft+22sOeesOuuabNFSTWmSxfYaaf8+ZlnZheLpLpkeiF10BdfFN/1fOONyx+LpDI75RQIuRWN//lPmDQp23gk1RUTd6mD3mhh79711y9vHJIysPrqaVxcg0ceySwUSfXHxF3qoGKJ++abQ+/e5Y9FUga23DJfHj06uzgk1R0Td6mDChP3VVeFY46Bq67KLh5JZVa4EdPDD2cXh6S6Y+IuteH552Hw4DQZ9euvGyfuxx4LF1+cEnhJdWLDDWGhhVJ5/Hj44INs45FUN0zcpTaccAK8/nrqWPvVr1K5wSqrZBeXpIz07Nl4nLvDZSSViYm71IYHHsiXzz4bnnoqf27iLtUpx7lLyoCJu9RBc+em48CBsOKK2cYiKSOF49xvvRXefTe7WCTVDRN3qQ0NGyU2dcUV0LVreWORVCE22CD/k9vnn8Nxx2Ubj6S6YOIutWLuXPjqq+b1iy/euMNNUp3p1g1Gjcqf338/zJuXXTyS6oKJu9SKTz4p/rd4yJD85omS6tSmm8JSS6XytGkwdmy28UiqeSbuUgtmzYKjjireNmRIeWORVIFCSEtDNvj3v7OLRVJdMHGXWnDttXDbbcXbVlutvLFIqlAbbZQvX3+9w2UkLVAm7lILzj+/5bZlly1fHJIqWOGykI88Ar//fWahSKp9Ju5SE3fcAaefDl98Ubx9iSVghx3KG5OkCvXtb8Pee+fPr7suu1gk1bxuWQcgVZLx42HXXfNrtRfaay/YZx8YOjStKiNJAFx8MdxwA8QIY8bAZ5/5JSFpgbDHXSrw5JPFk3aAY4+FbbaB5Zcvb0ySKly/frDeeqk8b17j7ZYlqYRM3KUC48YVr3/5ZVh//fLGIqmKjBiRLx9/fFpLVpJKzMRdAp54Ii39eOONzds23hi++c3yxySpiuy3H3TvnsrvvAMXXphtPJJqkom76t7f/552Qb3sMnjvvebtBxxQ/pgkVZkhQ9JY9wZ33JFdLJJqlom76trpp8Muu8Ds2c3bRo+G++6Dgw4qf1ySqtCPfgQ9e6byq6/Cm29mG4+kmmPirrp25ZXF61dcEYYPh5Ej0+aIktSm3r3hO9/Jn991V3axSKpJJu6qW/PmwaRJxdt++MPyxiKpRuy4Y758553ZxSGpJrmOu+rWtGn5pR/79IEJE9JykEss0XgXc0lqt+23z5cffRQmToSll84uHkk1xR531a3C1dr6908J+/bbwyabQBf/zZDUGcsum187dt68tKPbnDnZxiSpZpieqG5NnpwvL7lkdnFIqjFHHZUvP/mkY90llYyJu+rOnDnwt7+lFWMa9O+fXTySasx++8Fee+XP7703u1gk1RQTd9Wdc85Jv17/8pf5OnvcJZXUYYfly/fdBzFmF4ukmmHirroyZw6ccUbzenvcJZXURhvBooum8jvvwL//nW08kmqCibvqysMPF683cZdUUt27ww475M+POcZed0nzzcRddeXSS4vXO1RGUsmddRYstFAqP/ssPPNMtvFIqnom7qobzzwDd99dvM0ed0klN3Ag7Lln/vzvf88uFkk1wcRddWHevPRLdUvscZe0QOyyS75s4i5pPpm4q6bNmAE//jF07QpPP53qevSAcePgO99J54suCt/8ZnYxSqph3/0uLLxwKo8bl16S1Ekm7qppRxwBv/9947rDD4fVVkt7olx/fRp62rD4gySVVK9esPXW+fM77sguFklVz8RdNeuNN+Caa5rXN+xG3rMn7L03DB5c1rAk1Zudd86XTzwRVlgBbr01u3gkVS0Td9Wkq6+GVVct3tZSvSQtENttB9265c/ffx9OOim7eCRVLRN31Zxp0+DAA1tuN3GXVFZ9+8JeezWue+MNmDo1m3gkVS0Td9Wcl19uvb1v3/LEIUn/84tfpE2ZCo0Zk00skqqWibtqynnnwWabZR2FJDUxaFDzjST+859sYpFUtUzcVVNOPLH19m22KU8cktTMyJFw1VX58/PPh4kTs4tHUtUxcVfNmDWr5bbvfx823hguuqh88UhSM1ttlR8y89lncOqp2cYjqap0a/sSqbJ99hlcfjn06VO8vX9/uO228sYkSUWtvDKcdVb+58H77882HklVxR53Vb1TToGTT047pDY1YEDaZEmSKsZPf5rfTfXdd9PykJLUDibuqmoxwmWXFW9bZZX09/B73ytvTJLUqu7dYYMN8ucrrAD//W928UiqGibuqkqTJ8OwYbDYYi1fc9ddEEL5YpKkdtt448bnJ5yQTRySqoqJu6rSySenJZC/+KJ4+9FHw+qrlzcmSWq373+/8fndd8Mf/pBNLJKqhom7qlJb49aXWqo8cUhSp6y3HjzzDHQrWCPiiCPg4Yezi0lSxTNxV01acsmsI5CkNqy/Powd27junnuyiUVSVTBxV1Vqa+y6Pe6SqsIqq8ANN+TPL7gAjj8+zbyXpCZM3FWV2vqb1tKa7pJUcUaObHz+m9/A6NHZxCKpopm4q+rMmJFehbo0+Sd5lVXKF48kzZd+/Zp/ad11VzaxSKpoJu6qOh9+2LyuWzd48EH49rfh7LNhxRXLH5ckddqhhzY+v+EGmDs3m1gkVSwTd1WdYpsMdu8OI0bAv/+ddlKVpKry05/CP/6RP580CfbZx7HukhoxcVfVmTCheV2/fmUPQ5JKp2tX2HZb+MlP8nU33eSOqpIaMXFXVZk4EQ47rHm9+5ZIqgnnnw9Dh+bPH3ggu1gkVRwTd1WNSZPS/K3Ciamnnw5//StsvXV2cUlSyXTvDj/+cf78vvuyi0VSxenW9iVSZbjpJvjyy/z5yJFwxhmZhSNJC0bh8pCjR6efGpdeOrt4JFUMe9xVNW6/vfH5H/+YTRyStECttBIMG5bKM2emFWearoErqS6ZuKsqTJkCjz2WyiHARx+lv22SVJNOOy1fvvNO2G03V5iRZOKu6vDSSzBvXiqvtx4ss0y28UjSArXDDrDTTvnzu+92Fr4kE3dVh/Hj8+U11sguDkkqixDgtttgv/3ydUceCddem11MkjJn4q6K89JL8PHHjesKE/fBg8sbjyRlomtX+N3vYM0183XHHpvGDkqqSybuqihXXw1rrQUrrwzvvQfXXAMbbgi//W3+mlVXzSw8SSqvRRZJE3waJvV8+in87GeZhiQpOybuqhjjxsGBB6byjBnwjW/AAQfA0083vs4ed6kyhBD6hRAODiHcHkJ4I4TwdQhhWgjhiRDCQSEE/8aUQt++cNFF+fM//xnuuCO7eCRlxi9VVYTHHoMhQ9p37SqrLNhYJLXbbsCVwLeBp4GLgNuAbwJXAX8NIYTswqshO+0E++yTPz/++LQrnaS6YuKuinDcce27bvDg9MuxpIowHtgRWD7GuHeM8aQY44HA6sB7wK7A97MMsKb8+tdp0irA66+nTZlefjnbmCSVVckS9xDC8iGEUSGED0MIM0MIE0IIF4UQlpiPZ24eQpgbQoghhLNLFasqz3//23Lbm2/CVVfBNtu46ZJUSWKMD8cY74oxzmtS/zHQsHbh8LIHVquWXx4237xx3SWXZBOLpEyUJHEPIQwCxgAHAM8AFwJvAT8B/hVC6NeJZy4K/BmYXooYVdmWaOE/79ZcEwYOhIMOgnvugeHDyxqWpM6bnTvOyTSKWnPkkY3Pb7nFXVWlOlKqHvfLgKWAY2KMO8cYT4wxbkVK4FcDzunEMy8GFgN+XaIYVaE++ADef79424orljcWSfMvhNAN+FHu9N523jOm2Is07EYNfvhDuO++/Pm0aXDrrdnFI6ms5jtxDyEMBEYCE4DfN2k+HfgK2DeE0LsDz9yJ1Ht/DPDh/MaoyjVqVPr1tyWFc7EkVY1zSRNU74kx3tfWxeqgkSPh7ILRo8ccA0OHwllnZReTpLIoRY/7Vrnj/UXGOX4BPAksDGzYnoeFEJYirVLw9xjj9SWITxXq4YfTEJhieveG/feH3Xcva0iS5lMI4RjgZ8A4YN/23hdjXK/YK/ccNXXEEbDwwqn86afwyivwi1/AX/+abVySFqhSJO6r5Y7jW2h/PXds7+rbV5DiOryzAfmTa2V59lnYYgs48cR83Zw5cNRRxa+fOhW+/DJtxtTFdY+kqhFCOIo0zPG/wJYxxqkZh1S7+vZt/KXa4OijYebM8scjqSxKkRYtljtOa6G9oX7xth4UQjgQ2Ak4MsY4sQSxqQIceGBap/288+Chh1LdU0+lDZeaOumklieqSqpcIYRjgd8Br5CS9o8zDqn2nXoqPPMM3HVXvm7SJHjwwexikrRAdSvDezRsvhFbvSiElUibd9wSY5yv3/pyP68We48xwLrz82x1XOEyw3ffDWPHpk6hBnvuCb16wWefNa6XVB1CCCeQxrW/AHw3xvhJxiHVhxBg/fVT+fjj4fzzU/mii9LM/m9+M7vYJC0Qpehxb+hRX6yF9j5NrmvJKOBr4Mg2rlMVe+MNOPbYxnWbbw5/+hPcdhssu2w2cUnqnBDCaaSkfQwwwqQ9I7vtli8/+GCarHq2259ItaYUPe6v5Y4tjWFfNXdsaQx8g3VJyf/kFnbIPiWEcApwR4xx5w5HqUzEJr+z3H1382s22KA8sUgqrRDCfsAvgbnA48AxRb6/J8QYrylzaPVn2DD49rfh6afzdRdcAD//OfTokV1ckkqqFIn76NxxZAihS+HKMrlNlDYh9aT/u43nXEtafaapVYHNST/BjgGen++IVTbT2vqdhdQxJKkqrZw7dgWObeGaR4FryhJNPQsBRo9Oa7r//Ofw8cdp/OHZZ8OZZ6Z2SVVvvhP3GOObIYT7SWu5HwVcWtB8JtAb+GOM8auGyhDC6rl7xxU855hizw8h7E9K3P8RYzx1fuNVeU2e3Hr7brtB9+7liUVSacUYzwDOyDgMNejVC/bdF55/Hi68MNWddRYsvjj89KfZxiapJEq12N6RwCTgkhDC30MIvw4hPAz8H2mIzClNrh+be6mGvfwyDG5lEdA//xmuuaZs4UhSfdhjj8bn556b1tiVVPVKkrjHGN8EhpF+Dv02afONQcAlwEYxximleB9Vl6aTUBv07p0WPfjRj/L7h0iSSmSDDeAPf8ifT54Miy7aeNlISVWpZMtBxhjfAw5o57XtHmyXm9R0TeeiUjnFCD/+cVru8dJL086oTV15JRxwAHTtWv74JKluHHYYvPQSXHZZvm7XXeFf/4L1iq6YLKkKuC+lSuaWW9LfiNGjYf/9m7cfeywcfLBJuySVxdFHN/5Zc/ZsOOGE9GX92mst3yepYpm4q2Ruvz1ffvbZ5u3uiCpJZbT66vDOO3Dnnfm6hx6CH/4wbdz0sZvbStXGxF0lM3t26+2fflqeOCRJOf37ww47wE47Na7/4oviG2tIqmgm7iqZthL3tdcuTxySpCb+8Ie0QVOh3/42rTgzvq39ESVVChN3lczMmS23bbkl7Lln+WKRJBVYZpk0MfWGG/J1Y8fCSSfBNtvAvHkt3yupYpi4q2QmTSpev+eeaYUZd92WpAyFALvvnobPFHrrLfjvf7OJSVKHmLirZD76qHj9MsuUNw5JUgu6dIEzzmjek/LEE5mEI6ljTNxVEnPmwMSJxds22aS8sUiSWnHUUWm1gDPPzNcdcUQaSiOpopm4q1NihFdeyY9rnzQp1TV16qnw/e+XNzZJUhsWXhi23rpx3e67t73KgKRMmbirU372Mxg6FAYPTgsSnHZa8etOOSUNq5QkVZh11oEVV8yfv/deGkJTuO67pIpi4q4OixH+/OdUfvddWG01GDWq+LU9e5YvLklSB3TvDk891Xwi0k47pS91V5qRKo6Juzps8mSYOjXrKCRJ823AAHjsseaTVQ86CK6+OpuYJLXIxF0dNnZsy22F+3scffSCj0WSNJ9WXTWt2bvLLo3rb7wxm3gktahb1gGo+rSWuJ98cmr/+GP4xS/KF5MkaT5sskl6PfJI2jEP4PHH4auvoHfvTEOTlGfirg6JsfXEfdgw2HHH8sUjSSqh4cNhzTXh1Vdh1qz0M+pxx8E++0A3UwYpaw6VUbs9/XQaDnnJJcXbV1wxtUuSqljhMpGvvgoHHABbbJF63885B1ZYAS67LLv4pDpm4q52O/HENASm0Nprp+NKK8Gf/lT2kCRJpXbssbDWWo3rnnoK9t8/bc7x/vtpE6e5czMJT6pnJu5ql7ffTkMfC625JowZA2+8Aa+/DiNGZBKaJKmUll8ennsORo+Ggw/O1996a+Pr3nmnvHFJMnFX28aOhYEDm9dvvjl06QKDBjn0UZJqSpcuabz7FVfA9tsXv2bcuLKGJMnEXe1w1VXN60KAQw8tfyySpDIKAf7yF1h//eZtra1UIGmBsJ9ULXrnndSh8sQT+bpll01DG9deOz++XZJUw/r0gXvvhe98B55/Pl9/3HGw4YZpi+x1101JvqQFysRdRU2eDGusAdOnN64fMyYl75KkOtK3LzzzTFpV5owz8vWbbpqOl10GRxyRSWhSPXGojIC0Pvt//wszZ6bzJ59snrT362fSLkl1q1u3lsdInnMOfP11eeOR6pCJuwA45pi0SsyKK6YdT//zn+bXbL55+eOSJFWQZZeF889vXv/BB7DMMnDjjfDJJ+WPS6oTDpURANdfn44TJ8JZZxW/5qCDyhePJKlCHXccrLNOGvNe6PPPYa+9YPHF0+SoNdfMJj6phtnjLqZNg88+a7n9F7+At96C7bYrX0ySpAo2YgRcfnnxts8+Sz/jxljemKQ6YOKuNvfQGDYMVl65PLFIkqrE4YfD739fvO3hh+E3vylvPFIdMHFXm4n7gAHliUOSVGX23x923DFNgnrhBTjkkHzbCSekMe+SSsbEvY598QVcfTUcfXS+rtja7CbukqSiFl4Y7rgDHn0U1loLLr0UNtsstcWYxrz/+McOm5FKxMS9Tj33HAwcCAce2LjHfZdd0nK9hZZaqryxSZKq1EILwe23wyqr5Ot+/3sYNSq7mKQaYuJep84/v/iKXQMHwvDhjeu6di1LSJKkWtCvX+qBHzEiX3fMMTB+fHYxSTXCxL0OzZ0LDzxQvG3FFeHEE/Pnhd+7kiS1y4ABcOedMGRIOp8+PS0f+fLL2cYlVTkT9zr0/PMwZUoqL7UU7LNPKi+5JKy7Lqy/Pvzxj/DDH8Jvf5tdnJKkKrbwwnDDDdC9ezp/7z341rdg5Eh4881sY5OqlIl7nYkRLrwwfz5yJPzpT3DPPfDSS9C7d6o/9FC4+eb0HStJUqesvTbcdlvjMZcPPABHHpldTFIVM3GvMw8+mDpAGuyxB/ToAdtsk3arliSppHbYIS0NWej+++HDD7OJR6piJu515rHH8uUdd3Q3VElSGfz0p2n1g0LLLZfGZP7jH9nEJFUhE/c6ESNcdhmcfXa+bscds4tHklRH+vVL4zFPO61x/S23wPbbpx54SW0yca8Tf/kLHHVU47qVVsokFElSPerdO23GVMy555Y3FqlKmbjXga++gn33bV5v4i5JKqulloIQmtePHg3PPFP+eKQqY+JeB1pas32FFcobhyRJnHlm8fojj4QZM8obi1RlTEEKQHUAACAASURBVNzrwOjRxet79ChvHJIkccwxaS3izTdPf6C65FKRMWOgV680Hv43v8k2RqlCmbjXqIkT02TU8eNbTtwlSSq7xRaD++6DRx+F4cObr+k+dSr8/Ofw+uuZhCdVMhP3GrXHHmky6mqrFd9heo89yh+TJEnNXHQRXHwx9OmTr4sRBg+2511qwsS9Bs2dC4880rx+003TJNUtt4Szzip7WJIkNde1axo+8+qraQhNoZNPho8+yiYuqQJ1yzoAld7HHxevP+kk2Hbb8sYiSVK7LL883HMPbLghPPtsqps9G4YMSSvODB6cbXxSBbDHvYbMnp1+XXzvveZt66wD22xT/pgkSWq3rl3h8cfTGPcG06bBYYdlF5NUQUzca8Rjj0H//rDqqnDbbc3bTz21+NK5kiRVlJ494Ve/gl13zdc98ggMGgQ77ZRWX5DqlIl7jbj8cvj8c3jzzeZzeTbdFHbeOZu4JEnqsK5d4dZbYfvt83VvvQV33plWonn//cxCk7Jk4l4j7ruveP3OO6e2Lv4/LUmqNied1Lxu3Lj08/Jbb5U/HiljpnM1YN48+Prr4m277w4LL1zeeCRJKomNNy4+vn3GDLjhhvLHI2XMVWVqwLvvtrxL9HLLlTcWSZJK6sILoXfvNEn19dfTpC6Ae+9NE7ikOmLiXgPGjcuXN9sMunVLu6UusggMHZpdXJIkzbdeveCCC1J58mRYeum0hNqTT8L3vw+HHOKyaaobDpWpAYWJ++qrw/XXwznnwP33w+KLZxeXJEklteSSMGxY/vz222G77YovpybVIBP3GtCwTwWkfSoGDEibzW20UXYxSZK0QJx/Piy0UP48RthzTzjgADjxRPjww+xikxYwE/cqFyM89FD+fPPNs4tFkqQFbost4NVX4YQT8nWzZ8M118B556XJXSefnMbESzXGxL2KzZoFTzwBH3+czpdYAtZeO9uYJEla4AYNgnPPTUtCLrts8/Zf/zr1vks1xsS9Cj31VNoNunfvxj3sW22V9qyQJKkurLwyvPhi2mm1qT/8If0sLdUQE/cq8+mn8N3vpiF+c+Y0bhsxIpuYJEnKzJJLpo2aHn+8edsaa8CECWUPSVpQTNyrzJgxMH168bbvfKe8sUiSVDE23RSuvrpx3bhxqVd+ww2dtKqaYOJeZb74ouW2VVYpXxySJFWc/feHK69sXv/007DttvD552UPSSolE/cqM2lS8fqDD4YQyhuLJEkV50c/goMOgh49Gte/+CL88IeOe1dVM3GvMhMnNq8bMQJOO638sUiSVHF69ICrroKZM9Mykb/7Xb7tvvvgjDNcKlJVy8S9yjTtcf/rX+HBB+Eb3/j/7d15mFxFufjx7xuGyxL28CPshjUooAhhDVsIsgkCV1wQFHG7CojIIghetoDkKpugiF5FFFDEjU0QZJNNZFfRhLAYdhASICFsIanfH3Xmdk9PTzKT6enTPfP9PM95TnfV6dPv1MzUvFNdp0458UiS1LI6OuDgg2G//SplJ58MG28M06eXF5e0gEzc20x14n7hhfCRj5QWiiRJ7WGnnbo+f/xxOPTQPG1mzpxyYpIWgIl7m6lO3Fddtbw4JElqG9ts073skktgmWVgiSXg5z9vfkzSAjBxbzPVifvIkeXFIUlS2xg1qv5o14wZ8OabcOyxXrSqtmDi3ib+8Q847DCYNKlStsIK5cUjSVLbiICJE/MfzjFjutc/8QSssw4880zzY5P6wMS9DbzyCmy/PXznO5WyCBgxorSQJElqL/vtl5dmu+ceOOMMWG65rvWPPQZf/GI5sUm9ZOLeBiZOhJde6lq2wgqw0ELlxCNJUls7/PA89/SHP+xafvXVsNRS3mVVLcvEvcXNnt29XwHYe+/mxyJJ0qCx0EL5Tqsf/WjX8pkz4bTT4KGHuo+aSSUzcW9RjzySV69ad114+eWudSNGwIQJ5cQlSdKgsfDC8Mtf5j+61b77XdhwQ9hoI3juuXJik+owcW9REyfCH/8IU6dWyrbZBo45Bu64A5ZfvrTQJEkaXNZeG95+GxZfvGv5M8/AZpvBv/5VTlxSDRP3FnXBBd3LJkzIn96NHt38eCRJGtQWXjjflKnW00/DVlvllSKkkpm4t6gll+z6fNw42HbbcmKRJGlIOP74+rckf/75PKI2dy68/nrz45IKDUvcI2LViLggIp6NiLciYmpEnB0Ry/by9cMjYr+I+HlETI6IWRExMyLujYgjIuI/GhVrq5s1K18b0+k978k3dYsoLyZJkga9xRaDyy6DyZPh2mu71h1xBKy/PgwfnufASyVoSOIeEWsB9wEHAncDZwGPA18B/hwRvVlxfBvgYmBn4CHgXOAXwCrA6cDNEbFoI+JtZa++CptvXnm+6qrw17/CiiuWF5Mk9SQi9omIcyPitoiYEREpIi4uOy6pX0aPhl12yaPr1ReVTZ6c90cfDS++WE5sGtIaNeJ+HrACcGhKaa+U0jEppR3ICfxo4NRenON5YH9gpZTSPsU5vgCsC9wPbAUc3KB4W9aZZ+a7pHYaPRo6OsqLR5Lm4xvAIcBGgLed1OCy2GJw9tndy19/Pa8iITVZvxP3iFgT2AmYCnyvpvoEYBbwyYgYPq/zpJQeTCldklJ6u6Z8JnBG8XT7/sbb6mr7gf/3/8qJQ5J66avkAZalgC+VHIvUePvtB8cdByNHdi0/88y84swz/r+q5mnEiPsOxf76lNLc6ooi6b4DWBzYoh/vMbvYv9ObgyPivnobsF4/Yhhwzz6bV6Oqtvrq5cQiSb2RUro5pfRISimVHYs0YE45JV+gOmcO7LBDpfyee3JSLzVJIxL3zsUJp/RQ33lXg3X78R6fKfZ/6Mc5Wt4f/9j1eUcH7L9/ObFIkqQaw4bBhRfmu652+ulP4ayzYMaMfLtzaQA1InFfuti/2kN9Z/kyC3LyiDgE2AV4EKizunl3KaVN6m3A5AWJoVnuv7/y+GMfyzdy23DD8uKRpGZp109KNQStthq8+Wae/97p8MNh6aXzWs4HHphH5qUB0Ix13DsXMezzx6gR8Z/A2eQLVz+cUhrU/8r+7W+Vx5/4BIwaVVookiSpJx0dcMIJ3cvfeiuPyP/4x00PSUNDI9Yr6RxRX7qH+qVqjuuViNgLuBT4NzAupfT4goXX+ubOzb//t9xSKXvve0sLR5KarvhUtJti1H3jJocjzd8RR+Q1nH/+c3jiia51xx0Hn/xk11F5qQEaMeL+cLHvaQ77OsW+pznw3UTER4BfAS8A26WUHp7PS9raxRfn6146DRsG73pXefFIkqT56OiAb34Tpk7NCfy0abDyyrnupZdg003hwQdz+X335VE6qZ8akbjfXOx3iogu54uIJYGxwBvAXb05WUR8gnzjpWfJSfsj83lJW3vnHTj55K5la63lXVIlSWobSy0Fyy0He+1VKfvHP+D97883cBozBo4/vrz4NGj0O3FPKT0GXA+MovsNkk4ChgM/SynN6iyMiPUiotsFRxFxAHAR8CSw7WCeHtPpqqvgsce6ln30o+XEIkmS+mG77XquO+sseOWV5sWiQalR9+Q8CLgTOCcixgOTgM2BceQpMrWLnE4q9v83rhwR48irxgwjj+IfGN2HnV9JKdW5hVn7Ov/8yuN3vxu+8IW8SZKkNrPttj3Xvf46nHEGTJjQvHg06DQkcU8pPRYRY4CTyUs37gY8B5wDnJRSmt6L07yLyicAn+nhmCfIq8y0vQcegGOPheuvz88j4Nprndsuqb0UCwl0zg9YsdhvGREXFo9fSikd2fTApDKsuCJsv31ltYnVV89z259+Oj8/5ZQ89/1DHyorQrW5Ro24k1J6Cjiwl8d2G0pPKV0IXNioeFrZO+/AHnt0vUvyHnuYtEtqSxsBB9SUrVlskAdcTNw1dPz2t/CHP+TR91VWyUtEbrcd/OUvuf6cc/J678stB+97X7mxqu00Yx131bjjjq5JO9RfDlaSWl1K6cSUUsxjG1V2jFJTLbss7LtvTtoBFlkkLxnZ6cYbYYcdYJNN4IoryolRbcvEvQRXXdX1+SGHwMauUixJ0uC05pp5ZZlqc+bkVWgmTHCpSPWaiXsJqhP3X/wCzj23vFgkSVITVC8VWe344/OW+nyDeQ1BJu5N9uSTMKW4FdVii/X8eyxJkgaRww6DzTarX3fqqXDQQTB7dnNjUtsxcW+iJ5+Eyy+vPN9mG1h00fLikSRJTTJ8eL7I7dJL4cor80WrH/hApf788/P8+EMOgUcG9b0n1Q8m7k1y0UV51ZivfKVSNn58efFIkqQm6+iAj30sLyX3H/+RL07dd99K/axZ8L3v5Qvffvvb8uJUyzJxb5JvfrN72Y47Nj8OSZLUIhZbDC65pPtNmV57DT78Yfj+98uJSy3LxL1JJk/u+nztteH97y8nFkmS1CIi4BvfyHdh3H33rnUHHQQrrwz/+Ec5sanlmLg3wZw53cuOOir/rkqSJLHLLnnZuenTu64R/dxz8KlP1U8mNOSYuDdB552OO+26a/4dlCRJ6mLZZeGXv4Tll6+U3X8/HHooPPFEeXGpJZi4N8Hjj1ceb7UVXHONq8lIkqQerL12HvU76KBK2XnnwahRsPfe+SJWDUkm7k1QnbivuWZ5cUiSpDaxyCJwxhk5ia92+eWwxBLwP//j9JkhyMR9gM2ZAyefXHm+xhrlxSJJktrIoovCz34GI0Z0rzvmmLwO/NSpTQ9L5TFxH2DnnZdvvNTp3e8uLxZJktRmttwSXnwRUsqrz1S7+WYYN86pM0OIifsA+81vKo+32CJPTZMkSeq1zmXoJkzIc9+r7+Y4dWr3hF6Dlon7AJo1C/7858rz3/7Wi1IlSVI/rLIKnH02nH9+pezss+E738kf8d97L8yeXV58GlAm7gPo9tvh7bfz4/XXh5VWKjceSZI0SHz+87DbbpXnhx0G73oXbLoprL46PPRQebFpwJi4D6Df/a7yePz48uKQJEmDzLBhcNlleZ3pWs8/DzvuCNOmNT8uDSgT9wHy0EPwgx9Unu+zT3mxSJKkQWj4cPj972HzzbvXvfBCvonTvfc2Py4NmI6yAxiMpkyBDTesPF99dRg7trx4JEnSILXMMnDbbfCjH+ULV+++G264oVI/blyeVrPGGrDTTjB6dHmxqt9M3AfAued2ff6FL+RPtCRJkhpu4YXhS1/Kj//9b9h3X7jppvz8tdfgrLPy4wj4xCfg9NNhxRXLiVX9YjrZYLNm5XsldPrUp+BrXysvHkmSNISssALceCNcdVW++2q1lOCSS2CXXbzrapsycW+wW2+FGTPy43XWgQsvzP8IS5IkNc3uu8Odd8LHPgaf+xzssEOl7q9/hSuuKC82LTCnyjTY3XdXHu+8c+WeCZIkSU218cZw6aWV50cfDd/6Vn583HHw+ON55Zljj4UllywnRvWJI+4Nds89lcebbVZeHJIkSV0cfjgsvnh+PHkyHHUUTJyYL8abMweuvBIeeKDcGDVPJu4NlFLXEXcTd0mS1DJGjoQJE7qXX3opdHTAnnvmpSXvu6/5salXTNwb6Kmn4MUX8+Ollspz3CVJklrGoYfCIYfkRL2e2bPhtNOaG5N6zcS9gf75z8rj973PJSAlSVKL6ejI61a//HIeWa83yvi733VNal55Jc8Fnju3eXGqLlPLBnr44cpj728gSZJa1hJL5ItX//73PFXmpJMqdXPnwvrrw6mnwsyZeTRys83ynHiVysS9gaZMqTw2cZckSS1vkUXykpHHH5+XiVxooUrdN74B48fDk0/m52eemS/oU2lM3BvIEXdJktS23vveriPv0HW5POg6SqmmM3FvoOrEfd11y4tDkiRpgXSu777SSvXrx4/PI++zZzc3LgEm7v328stw/vlw7bXw9NO5rKMD1lyz3LgkSZIWyBprwAUX1K975hk44gj42tecNlMCE/d+OuAA+NKXYLfdKmWbbw4LL1xeTJIkSf2y885w8MGw6KL5QtZaZ5+dy6tXn9GAM3Hvp6uu6l7WeTdhSZKkthQB3/0uvPFGXlnmggtgv/26XsT3+ut59ZmxY+GGG8qLdQgxce+HmTO7lx10EGy1VfNjkSRJGjAHHggXXwyXXJJH4avdeSfsuis8+GA5sQ0hJu798NRTXZ+PGwdnnFFOLJIkSQNuk01g2rQ8Ar/YYpXyd96BY4/NS0iOHp0TfDWciXs/dC5rCvln9IYbuv8TKkmSNKgsvngegX/5Zbj66kr5tdfmmzZNmQL/9V8wa1Z5MQ5SJu79UJ24b7klDLM1JUnSULHIIvDBD8LnPte9btYsWHZZ2HPPPJVGDWGq2Q/Viftqq5UXhyRJUmm+/32YODEn8tVmz4Yrr8wXr668cl6l5u23y4mxWkr5k4Jf/CJP8WkjJu79UD3HffXVy4tDkiSpNB0dcPTR8NBDcMwx9Y957jk47zw4/XSYO7e58dW65RbYYw/4xCfyBbdtxMS9H6ZOrTw2cZckSUPa2mvDaafBNdfANtvUP+a44/ISkpMnNze2atVTew48sLw4FoCJ+wJ65x24//7K8/XWKy8WSZKklrHrrnDrrXlKysknd6+fPBm23houvXTeU2fmzoXLL4f77mtsfG+80djzNZGJex+lBHfdlT9Zee21XLbaao64S5IkdfP1r8Pxx3cvnzYN9t0X1l03199+O8yZ0/WYiRNh771h0029Q2vBxL2PLrssryBT/cnK2LHlxSNJktSyOjrgpJPgL3+BpZbqXv/EEzBhQp5aM3Ik7LJLHpGfMydPq4E8anrZZc2Nu0WZuPfReed1L9t66+bHIUmS1DY22yyv+z57Njz6KHzhC7D00l2PmTYNrrsu34b+xhu71t1yC3z60/Cb3/Q/lpT6f46SmLj3Ub2lSD/4webHIUmS1FaGDcsj8GutBT/4QU7gf/Qj+PznuybxN98MO+/c9bV/+hP89Kd5JZjnn29u3C3ExL0Pnnuu+3KfP/4xjBpVSjiSJEnta/nl4bOfhR/+EKZPhw03nP9r3n4bVlopz49f0JVpHHEfGu65p+vz22+Hz3ymnFgkSZIGjWHD4MQTe3/8pZfmtdgX5AZKtRfB1j5vYSbuffCXv1QeH3aYF6VKkiQ1zN57w7e+1fvjH30UNt44j6LedFPvXzdz5ryftzAT9z64/fbKY5N2SZKkBoqAo47KF7Cec07e1l9/3q/5+9/hJz+B8eN7dxfUN9+Et97qWvbqqwsec5OZuPfS22/D3XdXnpu4S5IkDYCODvjyl/M2Zkz3+v32g+WW617+5S/nlWvmpV6S3kaJe0fZAbSL++/P/6QBrLlmvi5CkiRJA2jiRBgxIq868+lP57teRsA118Duu3e90PSVV/KxW28NO+4IyywD73lPHo2PqBxTy8R98KmeJuO67ZIkSU2w4opwxhndy3fbLa/t/uCDeWrNkUfm8pTgttvyVm3MmHyH1pEju5/LxH3wMXGXJElqIdtum7eUYPHF4fTT4fHH6x97773woQ/Bllt2r2ujxN057r2QEtxxR+W5ibskSVKLiIAvfQkeewyefBL23LPnY//85+5ljz5amQ8NcOut+c6uteuAtwAT916YMgVeeik/HjEC1luv3HgkSZJUx2qrweWX59VmXnsNLrpo/q858cR8N83nnoNnn813bf3f/4UPfrBrQt8CTNx74ZZbKo+32qpyfYMkSZJa0AYbwPDhsP/+MHcuHHNM1/qll+76/IUXYOWVYZVVKsn6iy/CFVc0J95eMnHvheuuqzweP768OCRJktRHEXDaaXnu8/TpeTT+5Zfh8MPn/9qPfxw23TRPn2kBJu7zMXs23Hhj5fnOO5cXiyRJkvph2WXzaHxEvpj1yivn/5p774U99oBJkwY+vvkwcZ+Pu++GGTPy49VWg9Gjy41HkiRJDRCRE/ITTqiUjRoF3/9+XjO+2owZ+dj53eBpgLkc5HxUz2/feWfnt0uSJA0qxx8PH/hA1zts7r03XH99vli10+67w5JLlhNjwcR9Pr7+9XxR8XXXwRZblB2NJEmSGmrYMBg7tmvZyJHwwAPw8MP5ItWXXspLRJbMxH0+hg2DjTbKmyRJkoaIFVbIWwtxjrskSZLUBkzcJUmSpDZg4i5JkiS1ARN3SZIkqQ2YuEuSJEltwMRdkiRJagMm7pIkSVIbMHGXJEmS2oCJuyRJktQGGpa4R8SqEXFBRDwbEW9FxNSIODsilu3jeZYrXje1OM+zxXlXbVSskiRJUrvpaMRJImIt4E5gBeAKYDKwGfAVYJeIGJtSmtaL84wozrMucBNwKbAecCDwwYjYMqX0eCNiliRJktpJo0bczyMn7YemlPZKKR2TUtoBOAsYDZzay/N8k5y0n5VSGl+cZy/yPwArFO8jSZIkDTn9TtwjYk1gJ2Aq8L2a6hOAWcAnI2L4fM4zHPhkcfwJNdXfLc6/c/F+kiRJ0pDSiBH3HYr99SmludUVKaWZwB3A4sAW8znPlsBiwB3F66rPMxe4vng6rt8RS5IkSW2mEXPcRxf7KT3UP0IekV8XuLGf56E4zzxFxH09VK03v9dKkiRJragRI+5LF/tXe6jvLF+mSeeRJEmSBp2GrCozH1HsU7POk1LapO4JIqZNmjRp8U02qVstSS1t0qRJAKNKDqPZRk2aNAn7bUntZiD67EYk7p0j4Uv3UL9UzXEDfZ55mfHGG29w//33T+3j6zqn2Ezux3urb2zz5rK9m29B2nwUMKPxobS0Bem3/XluPtu8+Wzz5mqJPrsRifvDxb6nuefrFPue5q43+jw9SimtsSCv65wz39NIvhrPNm8u27v5bPPeWZB+27ZtPtu8+Wzz5mqV9m7EHPebi/1OEdHlfBGxJDAWeAO4az7nuas4bmzxuurzDCNf4Fr9fpIkSdKQ0e/EPaX0GHmpxlHAwTXVJwHDgZ+llGZ1FkbEehHRZYWXlNJrwEXF8SfWnOeQ4vzXeedUSZIkDUWNujj1IOBO4JyIGA9MAjYnr7k+BTiu5vhJxT5qyo8FtgcOj4iNgLuBdwN7Av+m+z8GkiRJ0pDQiKkynaPuY4ALyQn7EcBawDnAlimlab08zzTyjZjOAdYuzrM58BNgk+J9JEmSpCGnYctBppSeAg7s5bG1I+3VddOBrxSbJEmSJCBS6u/y6pIkSZIGWkOmykiSJEkaWCbukiRJUhswcZckSZLagIm7JEmS1AZM3CVJkqQ2YOIuSZIktQETd0mSJKkNmLjPQ0SsGhEXRMSzEfFWREyNiLMjYtmyY2t1EbFPRJwbEbdFxIyISBFx8Xxes1VEXBMR0yPi9Yj4W0QcFhELzeM1u0fELRHxakS8FhF/iYgDGv8VtbaIGBERn4uI30XEoxHxRtEmt0fEZyOi7u+6bb7gIuJ/IuLGiHiqaO/pEfFARJwQESN6eI3tPYDssxecfXZz2Wc336Dps1NKbnU2YC3gBSABlwMTgZuK55OBEWXH2Mob8GDRVjOBScXji+dx/J7AO8BrwI+BbxftnIBf9fCaQ4r6l4DvAWcBTxVlp5fdBk1u7y8WX/ezwCXAacAFwCtF+a8pbrhmmzeszd8G7iraeSJwLnBP0RbPAKvZ3k39fthn96/97LOb29722c1v80HRZ5fekK26AdcVDf3lmvIzi/Lzy46xlTdgHLAOEMD28/ojACwF/Bt4CxhTVb4ocGfx2o/XvGYU8CYwDRhVVb4s8Gjxmi3LbocmtvcOwB7AsJryFYEni/b4sG3e0DZftIfyU4u2OM/2bur3wz67f+1nn93c9rbPbn6bD4o+u/SGbMUNWLNo4H/V+aVakvzf1yxgeNmxtsPWiz8Cnynqf1qnboei7k815ScX5Sf15XxDcQOOLdrjXNu8Ke39vqIt/mh7N63N7bMb25722eW2v312c9u7rfps57jXt0Oxvz6lNLe6IqU0E7gDWBzYotmBDVKd7f2HOnW3Aq8DW0XEIr18zbU1xwx1s4v9O1VltvnA2aPY/62qzPYeWPbZzeXP88Cyz26utuqzTdzrG13sp/RQ/0ixX7cJsQwFPbZ3Sukd8ihaB3lUrTeveY48urZqRCze2FDbS0R0AJ8qnlZ3JrZ5g0TEkRFxYkScFRG3ARPIfwAmVh1mew8s++zm8ud5gNhnD7x277M7+vPiQWzpYv9qD/Wd5cs0IZahYEHauzevGV4c93q/omtvE4ENgGtSStdVldvmjXMkMLLq+R+AT6eUXqwqs70Hln12c/nzPHDsswdeW/fZjrgvmCj2qdQoho4Fae8h/z2KiEOBI8hXwX+yry8v9rb5fKSUVkwpBfmisv8kj8A8EBEb9+E0tvfAsq2ay5/nBWCf3Rzt3mebuNfX+d/S0j3UL1VznPpnQdq7t6+Z0Y+42lZEHAx8B/gnMC6lNL3mENu8wVJKL6SUfgfsBIwAflZVbXsPLPvs5vLnucHss5uvXftsE/f6Hi72Pc2HXKfY9zSfUn3TY3sX8/3WIF+k83gvX7MS+eOop1NKQ+njPwAi4jDgu8BD5D8Az9c5zDYfICmlJ8h/fNePiOWLYtt7YNlnN5c/zw1kn12uduuzTdzru7nY71R797KIWBIYC7xBXshf/XdTsd+lTt225NUg7kwpvdXL1+xac8yQERFHk2/48CD5D8C/ezjUNh9YKxf7OcXe9h5Y9tnN5c9zg9hnt4z26bPLXj+zVTe8mUcj23J75n8zjxfp240O1sAbS9S2438XX/e9wHLzOdY2719brwesWKd8GJWbedxhezf1e2Kf3bi2tM9uTjvbZzevrQdNnx3FSVUjItYif3NWAK4g3wJ6c/Ld5aYAW6WUppUXYWuLiL2AvYqnKwI7kz9Suq0oeymldGTN8b8m/9BfCkwHPkReXunXwEdTzQ9rRHwZOIf8S/JL8u2M9wFWBc6oPv9gFxEHABeSRwvOpf5c3qkppQurXmObL6Dio+1vk9fzJCPe/QAACENJREFUfYzcHiOB7cgXOj0PjE8p/bPqNbb3ALLP7h/77Oayz26uQdVnl/1fUCtvwGrAT4DnisZ/gnzxyDz/M3ZLACeS/7vsaZta5zVjgWuAl8kfa/8d+Cqw0DzeZw/gT8BM8hqp9wAHlP31t2B7J+AW27xh7b0B8D3yx9svkec6vlq0xYk99RG294B/X+yzF7zt7LNbq73tsxvb3oOmz3bEXZIkSWoDXpwqSZIktQETd0mSJKkNmLhLkiRJbcDEXZIkSWoDJu6SJElSGzBxlyRJktqAibskSZLUBkzcJUmSpDZg4i5JkiS1ARN3SZIkqQ2YuEuSJEltwMRdbSEiloiIFBFXN+Bc90bEa42IS30XEacX38sxZcciaWDYZw8e9tmtxcRd81T8svZl+3TZMbejiNi9Tlu+HRFPR8SvImKLsmOU1Prss5vDPltl6Sg7ALW8k+qUHQYsDXwHeKWm7sEBimMW8G6gEaMuHwYWacB5BsIjwM+Lx0sAmwH7AHtHxJ4ppd+XFpmkdmCf3Vz22WoqE3fNU0rpxNqyYoRmaeDslNLUJsWRgMkNOtcTjTjPAJlS2+YRcQpwHDAR8I+ApB7ZZzedfbaayqkyGhCdcxIjYrGIOCUiHi0+RvxuUT8iIo6JiD9FxLNF3QsR8ZuI2LjO+erOl6yeexcR+0XEfRHxRkS8FBEXRcQKPcVWU9b5seeREbFZRFwXEa8WX8MNEbFJD1/n6hFxcfF+rxfv/7Hq8/WvJQH4cbHfICIWrRPDckU7PBoRb0XEtIj4fURsU+fYQ4q49qlT17A2Ll63ZdF2r0XEKxHxh3rfW0nls8+2z7bPbg+OuGsgDQOuBkYD1wHTgM6Rk/eTP9K9BbgCeBVYA/gQsHtEfCCldGsf3utrwO7FuW4GxgL7kzvOMSmlOb08z9bAKUVc/wusCewF3BIRG1SP/ETEqsCfgZWBG4F7gFWAnwLX9iH2+YliP7fYKhW5A74TWKvY/wpYEfgosEtEfDqldFGD4uh1G0fEjuSRpmFFTFOBTYHbi01S67HPbgz7bA2clJKbW5828i90AkbN45h7i2PuBpapU78csGyd8rWAl4B7asqXKM53dU356UX5NGDdqvIgd1YJ2K1ObK/VlO1eHJuAfWrqjijKv1VT/sui/L9ryrcA3inqjuxlm3a+/9V16iYWdX+uU3dJUXdmTfkGwOvFNrKq/JB6X2Mj25g8IPBEUb5jzbmOq2rnMWX/LLu5DYXNPvv/yu2z7bPbfnOqjAba11NKtRdDkVKanlJ6uU75Y8CVwJiIGNGH9/l2SmlK1XkS8KPi6WZ9OM91KaVf15T9sPY8EbEk8J/Av4FvVx+cUrqLPGKxINaNiBOL7fSIuA04GpgOHFx9YEQsQR6lmQ4cXxPDQ8APgMWA/RYwllq9bePxwOrANSmlG2rPATzToHgkNZ59dt/YZ6upnCqjgXZ3TxURMQ74MrkDWQFYuOaQlckjBr1xb52yp4r9sr08R93zpJRmRsSrNefZgPz7c19K6c0657kd+Hgf3rfTOsAJNWUvAtullCbVlG9YxHBPSqneyg03kVeTeP8CxFFPb9u4c07kn2oPTim9HRF3kVeJkNR67LP7xj5bTWXiroH0ekppZr2KiNgf+Bl5qbA/Av8iLx+WgJ2ALenb8l/dRojIH30CLNTP83Seq/o8Sxf7F3o4vqfy+fl9Sml3gIhYHtgXOBO4OiI2TSlNrxPDcz2cq7N8mQWMpVZv23h+bfN8g+KR1Fj22X1nn62mMnHXQErzqDsFmAm8P6X0eHVFRKxD/iPQymYU+5E91PdU3msppZeAcyNicfKcybOBT1Ud8mqxX7GHU6xUcxxULpSq97vfqD8Wne/XUxv0FK+kctln94N9tprBOe5quojoAN4FPFjnD8DCtP4fAIC/k0cuNqm33Bd5pYNGOQt4HNg/IjaqE8OmETG8zuvGFfv7q8o656iuVuf4Rt3OuvP9tqutiIj/IF8IJqlN2Gf3mX22BoyJu5oupfQO+WKX9YuPFgGIiGHAaeQlxlpa8XHy5eR5nkdV10XE5sBHGvhebwMnk1cEOLWq/DXyBVUjgP+uieE9wH8Bb1C5qx9U5q9+MiIWqTp+BeCbDQr5RvI8yt2KJcaqHUVefk1Sm7DP7vN72WdrwDhVRmU5i7xk1d8i4rfkjwO3A0aR19PdtbzQeu0I8ijNyRGxLXlN4FXJqwZcRV5LeG7PL++Ti4GvkzvWsSmlO4ryr5JHQ46OiLHkC6xGFjEsCnw2pfR/8xNTSo9FxO+AvYEHIuIP5IuUdidfGPXu/gaaUnonIj5DXhP4moj4NXk5ujHk9voj8IH+vo+kprLP7hv7bA0IR9xVljOBL5JXIPgM+YKeKeTVCv5ZYly9llJ6ktwB/4J8Vf5XgfWBA8hr5UJlXmV/32sO+eYn0HUE5wVym51FHhU5gtzB3waMTyldWOd0+wPnkOdHHgxsRR41+3wjYi3iuoH8se9twJ7F+8wl/xH4W6PeR1LT2Gf37b3sszUgIi/rKamRIuI7wKHA1lUjLZKkFmSfrXZh4i71Q0SsnFJ6tqZsU+BW8k023lXMD5Uklcw+W+3OOe5S/0yKiPuBfwBvAqOpzPU82D8AktRS7LPV1hxxl/ohIk4DdiPfLnoJ8tJddwLfSindWWZskqSu7LPV7kzcJUmSpDbgqjKSJElSGzBxlyRJktqAibskSZLUBkzcJUmSpDZg4i5JkiS1ARN3SZIkqQ2YuEuSJEltwMRdkiRJagMm7pIkSVIbMHGXJEmS2oCJuyRJktQGTNwlSZKkNmDiLkmSJLWB/w+ZG89QHbOcLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 375
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'], color='b')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Training Round')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], color='r')\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel('Training Round')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating New Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary going backwards (with index as key and the note as the value)\n",
    "backward_dict = dict()\n",
    "for note in note_dict.keys():\n",
    "    index = note_dict[note]\n",
    "    backward_dict[index] = note\n",
    "\n",
    "# pick a random sequence from the input as a starting point for the prediction\n",
    "n = np.random.randint(0, len(input_notes)-1)\n",
    "sequence = input_notes[n]\n",
    "start_sequence = sequence.reshape(1, sequence_length, vocab_length)\n",
    "output = []\n",
    "\n",
    "\n",
    "# Generate song with numberOutputNotes notes\n",
    "for i in range(0, numberOutputNotes):\n",
    "    newNote = model.predict(start_sequence, verbose=0)\n",
    "    # Get the position with the highest probability\n",
    "    index = np.argmax(newNote)\n",
    "    encoded_note = np.zeros((vocab_length))\n",
    "    encoded_note[index] = 1\n",
    "    output.append(encoded_note)\n",
    "    sequence = start_sequence[0][1:]\n",
    "    start_sequence = np.concatenate((sequence, encoded_note.reshape(1, vocab_length)))\n",
    "    start_sequence = start_sequence.reshape(1, sequence_length, vocab_length)\n",
    "    \n",
    "\n",
    "# Now output is populated with notes in their string form\n",
    "# for element in output:\n",
    "#    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to MIDI format\n",
    "Code here to output to MIDI files taken from github repo https://github.com/Skuldur/Classical-Piano-Composer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing output file: output.mid\n"
     ]
    }
   ],
   "source": [
    "finalNotes = [] \n",
    "for element in output:\n",
    "    index = list(element).index(1)\n",
    "    finalNotes.append(backward_dict[index])\n",
    "    \n",
    "offset = 0\n",
    "output_notes = []\n",
    "    \n",
    "# create note and chord objects based on the values generated by the model\n",
    "for pattern in finalNotes:\n",
    "    # pattern is a chord\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        notes_in_chord = pattern.split('.')\n",
    "        notes = []\n",
    "        for current_note in notes_in_chord:\n",
    "            new_note = music21.note.Note(int(current_note))\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            notes.append(new_note)\n",
    "        new_chord = chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    # pattern is a note\n",
    "    else:\n",
    "        new_note = music21.note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # increase offset each iteration so that notes do not stack\n",
    "    offset += 0.5\n",
    "\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "midi_stream.write('midi', fp=output_file)\n",
    "print(f\"Done writing output file: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
